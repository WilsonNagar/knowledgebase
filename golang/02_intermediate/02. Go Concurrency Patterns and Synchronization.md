---
number: 2
title: "Go Concurrency Patterns and Synchronization"
slug: "go-concurrency-patterns-and-synchronization"
level: "intermediate"
tags: ["go", "concurrency-patterns", "mutex", "waitgroup", "context", "sync"]
prerequisites: ["go-concurrency-fundamentals"]
estimated_minutes: 110
contributors: []
diagrams: []
examples: []
canonical_id: "golang-intermediate-02"
---

# Go Concurrency Patterns and Synchronization

## Overview

This guide covers advanced concurrency patterns in Go including mutexes for mutual exclusion, WaitGroups for goroutine coordination, the Context package for cancellation and timeouts, worker pools, pipelines, and other synchronization primitives. Master these patterns to build robust concurrent applications.

## Deep Explanation

### Mutexes

Mutexes provide mutual exclusion to protect shared resources.

```go
import "sync"

var mu sync.Mutex
var counter int

func increment() {
    mu.Lock()
    defer mu.Unlock()
    counter++
}

// RWMutex for read-write locks
var rwmu sync.RWMutex
var data map[string]int

func read(key string) int {
    rwmu.RLock()
    defer rwmu.RUnlock()
    return data[key]
}

func write(key string, value int) {
    rwmu.Lock()
    defer rwmu.Unlock()
    data[key] = value
}
```

### WaitGroups

WaitGroups wait for a collection of goroutines to finish.

```go
var wg sync.WaitGroup

for i := 0; i < 10; i++ {
    wg.Add(1)
    go func(id int) {
        defer wg.Done()
        // Work
    }(i)
}

wg.Wait()  // Wait for all goroutines
```

### Context Package

Context provides cancellation, timeouts, and request-scoped values.

```go
import "context"

// WithCancel
ctx, cancel := context.WithCancel(context.Background())
defer cancel()

// WithTimeout
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
defer cancel()

// WithValue
ctx := context.WithValue(context.Background(), "key", "value")

// Check cancellation
select {
case <-ctx.Done():
    return ctx.Err()
default:
    // Continue
}
```

### Common Patterns

#### Worker Pool Pattern
```go
func workerPool(jobs <-chan Job, results chan<- Result, numWorkers int) {
    var wg sync.WaitGroup
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for job := range jobs {
                results <- process(job)
            }
        }()
    }
    go func() {
        wg.Wait()
        close(results)
    }()
}
```

#### Pipeline Pattern
```go
func pipeline(input <-chan int) <-chan int {
    stage1 := square(input)
    stage2 := add(stage1, 10)
    return multiply(stage2, 2)
}
```

## Real Code Examples

### Example: Thread-Safe Cache

```go
package main

import (
    "fmt"
    "sync"
    "time"
)

type Cache struct {
    mu    sync.RWMutex
    items map[string]Item
}

type Item struct {
    Value      interface{}
    Expiration int64
}

func NewCache() *Cache {
    return &Cache{
        items: make(map[string]Item),
    }
}

func (c *Cache) Get(key string) (interface{}, bool) {
    c.mu.RLock()
    defer c.mu.RUnlock()
    
    item, exists := c.items[key]
    if !exists {
        return nil, false
    }
    
    if time.Now().UnixNano() > item.Expiration {
        delete(c.items, key)
        return nil, false
    }
    
    return item.Value, true
}

func (c *Cache) Set(key string, value interface{}, ttl time.Duration) {
    c.mu.Lock()
    defer c.mu.Unlock()
    
    c.items[key] = Item{
        Value:      value,
        Expiration: time.Now().Add(ttl).UnixNano(),
    }
}

func main() {
    cache := NewCache()
    cache.Set("key1", "value1", time.Second)
    
    if value, ok := cache.Get("key1"); ok {
        fmt.Println(value)
    }
}
```

## Hard Use-Case: Distributed Task Queue

### Problem Statement

Implement a distributed task queue with worker pools, task prioritization, and graceful shutdown using Context.

### Solution

```go
package main

import (
    "context"
    "fmt"
    "sync"
    "time"
)

type Task struct {
    ID       int
    Priority int
    Data     interface{}
}

type TaskQueue struct {
    tasks     chan Task
    workers   int
    wg        sync.WaitGroup
    ctx       context.Context
    cancel    context.CancelFunc
}

func NewTaskQueue(workers int) *TaskQueue {
    ctx, cancel := context.WithCancel(context.Background())
    return &TaskQueue{
        tasks:   make(chan Task, 100),
        workers: workers,
        ctx:     ctx,
        cancel:  cancel,
    }
}

func (tq *TaskQueue) Start() {
    for i := 0; i < tq.workers; i++ {
        tq.wg.Add(1)
        go tq.worker(i)
    }
}

func (tq *TaskQueue) worker(id int) {
    defer tq.wg.Done()
    for {
        select {
        case task := <-tq.tasks:
            fmt.Printf("Worker %d processing task %d\n", id, task.ID)
            time.Sleep(100 * time.Millisecond)
        case <-tq.ctx.Done():
            return
        }
    }
}

func (tq *TaskQueue) AddTask(task Task) error {
    select {
    case tq.tasks <- task:
        return nil
    case <-tq.ctx.Done():
        return tq.ctx.Err()
    }
}

func (tq *TaskQueue) Shutdown() {
    tq.cancel()
    tq.wg.Wait()
    close(tq.tasks)
}

func main() {
    queue := NewTaskQueue(3)
    queue.Start()
    
    for i := 0; i < 10; i++ {
        queue.AddTask(Task{ID: i, Priority: i % 3})
    }
    
    time.Sleep(1 * time.Second)
    queue.Shutdown()
}
```

## Edge Cases and Pitfalls

### Common Mistakes

1. **Deadlock with Mutexes**
```go
// Bad: Locking same mutex twice
mu.Lock()
mu.Lock()  // Deadlock!

// Good: Use defer or unlock properly
mu.Lock()
defer mu.Unlock()
```

2. **Race Conditions**
```go
// Bad: Unsynchronized access
counter++  // Race condition

// Good: Protect with mutex
mu.Lock()
counter++
mu.Unlock()
```

## References and Further Reading

- [Go Context Package](https://pkg.go.dev/context)
- [Go sync Package](https://pkg.go.dev/sync)

## Quiz

### Question 1
What is the difference between Mutex and RWMutex?

**A)** No difference  
**B)** RWMutex allows multiple readers  
**C)** RWMutex is faster  
**D)** Mutex is for reading only

**Answer: B** - RWMutex allows multiple concurrent readers but exclusive writers.

### Question 2
What happens if you call WaitGroup.Wait() with no Add() calls?

**A)** Blocks forever  
**B)** Returns immediately  
**C)** Panic  
**D)** Error

**Answer: B** - If the counter is zero, Wait returns immediately.

## Related Topics

- [Go Concurrency Fundamentals](./01.%20Go%20Concurrency%20Fundamentals.md)
- [Advanced Concurrency in Go](../03_advanced/01.%20Advanced%20Concurrency%20in%20Go.md)

