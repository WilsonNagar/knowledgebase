---
number: 1
title: "Go Concurrency Fundamentals"
slug: "go-concurrency-fundamentals"
level: "intermediate"
tags: ["go", "goroutines", "channels", "select", "concurrency"]
prerequisites: ["go-packages-and-modules"]
estimated_minutes: 120
contributors: []
diagrams: []
examples: []
canonical_id: "golang-intermediate-01"
---

# Go Concurrency Fundamentals

## Overview

Go's concurrency model is built on goroutines (lightweight threads) and channels (communication primitives). This comprehensive guide covers goroutine creation and management, channel operations and patterns, the select statement for non-blocking operations, channel directions and buffering, and common concurrency patterns. Understanding these fundamentals is essential for writing concurrent Go programs.

## Deep Explanation

### Goroutines

Goroutines are lightweight threads managed by the Go runtime. They enable concurrent execution with minimal overhead.

#### Creating Goroutines

```go
// Basic goroutine
go func() {
    fmt.Println("Running in goroutine")
}()

// Goroutine with function
func sayHello() {
    fmt.Println("Hello")
}
go sayHello()

// Goroutine with parameters
go func(name string) {
    fmt.Printf("Hello, %s\n", name)
}("Alice")
```

#### Goroutine Lifecycle

```go
// Main goroutine waits
func main() {
    go func() {
        fmt.Println("Goroutine")
    }()
    time.Sleep(100 * time.Millisecond)  // Wait for goroutine
}

// Using WaitGroup (better approach)
var wg sync.WaitGroup
wg.Add(1)
go func() {
    defer wg.Done()
    fmt.Println("Goroutine")
}()
wg.Wait()
```

### Channels

Channels are typed conduits for communication between goroutines.

#### Channel Creation

```go
// Unbuffered channel
ch := make(chan int)

// Buffered channel
ch := make(chan int, 10)

// Channel directions
var sendOnly chan<- int  // Send only
var recvOnly <-chan int  // Receive only
```

#### Channel Operations

```go
ch := make(chan int)

// Send
ch <- 42

// Receive
value := <-ch
value, ok := <-ch  // ok indicates if channel is closed

// Close
close(ch)

// Range over channel
for value := range ch {
    fmt.Println(value)
}
```

#### Channel Patterns

```go
// Producer-Consumer
func producer(ch chan<- int) {
    for i := 0; i < 10; i++ {
        ch <- i
    }
    close(ch)
}

func consumer(ch <-chan int) {
    for value := range ch {
        fmt.Println(value)
    }
}

ch := make(chan int)
go producer(ch)
consumer(ch)

// Fan-out (one to many)
func fanOut(input <-chan int, outputs []chan<- int) {
    for value := range input {
        for _, out := range outputs {
            out <- value
        }
    }
    for _, out := range outputs {
        close(out)
    }
}

// Fan-in (many to one)
func fanIn(inputs []<-chan int, output chan<- int) {
    var wg sync.WaitGroup
    for _, in := range inputs {
        wg.Add(1)
        go func(ch <-chan int) {
            defer wg.Done()
            for value := range ch {
                output <- value
            }
        }(in)
    }
    go func() {
        wg.Wait()
        close(output)
    }()
}
```

### Select Statement

`select` allows a goroutine to wait on multiple channel operations.

#### Basic Select

```go
select {
case msg1 := <-ch1:
    fmt.Println("Received from ch1:", msg1)
case msg2 := <-ch2:
    fmt.Println("Received from ch2:", msg2)
case ch3 <- 42:
    fmt.Println("Sent to ch3")
default:
    fmt.Println("No channel ready")
}
```

#### Select Patterns

```go
// Timeout
select {
case value := <-ch:
    fmt.Println(value)
case <-time.After(5 * time.Second):
    fmt.Println("Timeout")
}

// Non-blocking
select {
case value := <-ch:
    fmt.Println(value)
default:
    fmt.Println("No value available")
}

// Multiple channels with timeout
for {
    select {
    case value := <-ch1:
        process(value)
    case value := <-ch2:
        process(value)
    case <-time.After(1 * time.Second):
        fmt.Println("Tick")
    }
}
```

## Real Code Examples

### Example: Worker Pool

```go
package main

import (
    "fmt"
    "sync"
)

type Job struct {
    ID     int
    Data   interface{}
}

type Result struct {
    Job    Job
    Output interface{}
    Error  error
}

func worker(id int, jobs <-chan Job, results chan<- Result, wg *sync.WaitGroup) {
    defer wg.Done()
    for job := range jobs {
        // Process job
        result := Result{
            Job:    job,
            Output: fmt.Sprintf("Processed job %d", job.ID),
        }
        results <- result
    }
}

func main() {
    numWorkers := 3
    numJobs := 10
    
    jobs := make(chan Job, numJobs)
    results := make(chan Result, numJobs)
    
    var wg sync.WaitGroup
    
    // Start workers
    for w := 1; w <= numWorkers; w++ {
        wg.Add(1)
        go worker(w, jobs, results, &wg)
    }
    
    // Send jobs
    for j := 1; j <= numJobs; j++ {
        jobs <- Job{ID: j, Data: j}
    }
    close(jobs)
    
    // Wait for workers and close results
    go func() {
        wg.Wait()
        close(results)
    }()
    
    // Collect results
    for result := range results {
        fmt.Printf("Job %d: %v\n", result.Job.ID, result.Output)
    }
}
```

## Hard Use-Case: Rate Limiter with Channels

### Problem Statement

Implement a rate limiter that allows a maximum number of operations per time window using channels and goroutines.

### Solution

```go
package main

import (
    "fmt"
    "time"
)

type RateLimiter struct {
    limit    int
    interval time.Duration
    tokens   chan struct{}
    ticker   *time.Ticker
}

func NewRateLimiter(limit int, interval time.Duration) *RateLimiter {
    rl := &RateLimiter{
        limit:    limit,
        interval: interval,
        tokens:   make(chan struct{}, limit),
        ticker:   time.NewTicker(interval / time.Duration(limit)),
    }
    
    // Fill initial tokens
    for i := 0; i < limit; i++ {
        rl.tokens <- struct{}{}
    }
    
    // Refill tokens
    go func() {
        for range rl.ticker.C {
            select {
            case rl.tokens <- struct{}{}:
            default:
            }
        }
    }()
    
    return rl
}

func (rl *RateLimiter) Allow() bool {
    select {
    case <-rl.tokens:
        return true
    default:
        return false
    }
}

func (rl *RateLimiter) Wait() {
    <-rl.tokens
}

func (rl *RateLimiter) Stop() {
    rl.ticker.Stop()
}

func main() {
    limiter := NewRateLimiter(5, time.Second)
    defer limiter.Stop()
    
    for i := 0; i < 20; i++ {
        if limiter.Allow() {
            fmt.Printf("Request %d allowed\n", i+1)
        } else {
            fmt.Printf("Request %d rate limited\n", i+1)
            limiter.Wait()
            fmt.Printf("Request %d allowed after wait\n", i+1)
        }
        time.Sleep(50 * time.Millisecond)
    }
}
```

## Edge Cases and Pitfalls

### Common Mistakes

1. **Goroutine Leaks**
```go
// Bad: Goroutine never terminates
go func() {
    for {
        // Infinite loop
    }
}()

// Good: Use context or done channel
ctx, cancel := context.WithCancel(context.Background())
defer cancel()
go func() {
    for {
        select {
        case <-ctx.Done():
            return
        default:
            // Work
        }
    }
}()
```

2. **Sending on Closed Channel**
```go
// Bad: Panic when sending to closed channel
ch := make(chan int)
close(ch)
ch <- 1  // Panic!

// Good: Check if channel is closed
select {
case ch <- value:
case <-ctx.Done():
    return
}
```

## References and Further Reading

- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
- [Effective Go - Concurrency](https://go.dev/doc/effective_go#concurrency)

## Quiz

### Question 1
What is the default buffer size of a channel created with `make(chan int)`?

**A)** 0 (unbuffered)  
**B)** 1  
**C)** 10  
**D)** Unlimited

**Answer: A** - Channels created without a buffer size are unbuffered (buffer size 0).

### Question 2
What happens when you send to an unbuffered channel and no receiver is ready?

**A)** The value is dropped  
**B)** The send blocks  
**C)** Panic  
**D)** Error returned

**Answer: B** - Unbuffered channels block until both sender and receiver are ready.

### Question 3
Can you close a channel multiple times?

**A)** Yes  
**B)** No, it causes a panic  
**C)** Yes, but it's ignored  
**D)** Only from the same goroutine

**Answer: B** - Closing an already closed channel causes a panic.

## Related Topics

- [Go Concurrency Patterns and Synchronization](../02_intermediate/02.%20Go%20Concurrency%20Patterns%20and%20Synchronization.md)
- [Go Error Handling and Defer](../01_beginners/04.%20Go%20Error%20Handling%20and%20Defer.md)

