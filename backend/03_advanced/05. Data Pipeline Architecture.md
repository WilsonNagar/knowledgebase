---
number: 5
title: "Data Pipeline Architecture"
slug: "data-pipeline-architecture"
level: "advanced"
tags: ["backend", "data-pipeline", "etl", "streaming", "batch-processing"]
prerequisites: ["kafka-message-streaming"]
estimated_minutes: 140
contributors: []
diagrams: []
examples: []
canonical_id: "backend-advanced-05"
---

# Data Pipeline Architecture

## Overview

Data pipelines process and move data between systems. This guide covers ETL/ELT patterns, batch vs streaming processing, data quality, schema evolution, and building robust data pipelines.

## Deep Explanation

### Pipeline Types

**ETL**: Extract, Transform, Load
**ELT**: Extract, Load, Transform
**Streaming**: Real-time processing
**Batch**: Scheduled processing

### Components

**Sources**: Databases, APIs, files
**Processors**: Transformations, validations
**Sinks**: Data warehouses, databases

## Real Code Examples

### Example: ETL Pipeline

```
Source (PostgreSQL) 
  → Extract (Kafka)
  → Transform (Spark)
  → Load (BigQuery)
```

## References and Further Reading

- Data Pipeline Design Patterns
- ETL Best Practices

## Quiz

### Question 1
What does ETL stand for?

**A)** Extract, Transfer, Load  
**B)** Extract, Transform, Load  
**C)** Export, Transform, Load  
**D)** Extract, Transform, Log

**Answer: B** - ETL stands for Extract, Transform, Load.

## Related Topics

- [Kafka Message Streaming](../02_intermediate/04.%20Kafka%20Message%20Streaming.md)
- [Google BigQuery Analytics](../02_intermediate/12.%20Google%20BigQuery%20Analytics.md)

