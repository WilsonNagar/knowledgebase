---
number: 3
title: "Redis Caching Strategies"
slug: "redis-caching-strategies"
level: "intermediate"
tags: ["backend", "redis", "caching", "in-memory", "performance"]
prerequisites: ["database-fundamentals"]
estimated_minutes: 105
contributors: []
diagrams: []
examples: []
canonical_id: "backend-intermediate-03"
---

# Redis Caching Strategies

## Overview

Redis is an in-memory data structure store used as a cache, message broker, and database. This guide covers Redis data structures, caching patterns, eviction policies, persistence options, clustering, and best practices for high-performance caching.

## Deep Explanation

### Data Structures

**Strings**:
```
SET user:123:name "John Doe"
GET user:123:name
SET user:123:visits 0
INCR user:123:visits
```

**Hashes**:
```
HSET user:123 name "John" email "john@example.com"
HGET user:123 name
HGETALL user:123
```

**Lists**:
```
LPUSH tasks "task1"
RPUSH tasks "task2"
LRANGE tasks 0 -1
```

**Sets**:
```
SADD tags "redis" "cache" "database"
SMEMBERS tags
SISMEMBER tags "redis"
```

**Sorted Sets**:
```
ZADD leaderboard 100 "player1"
ZADD leaderboard 200 "player2"
ZRANGE leaderboard 0 -1 WITHSCORES
```

### Caching Patterns

**Cache-Aside (Lazy Loading)**:
```
1. Check cache
2. If miss, query database
3. Store in cache
4. Return data
```

**Write-Through**:
```
1. Write to database
2. Write to cache
3. Return success
```

**Write-Back (Write-Behind)**:
```
1. Write to cache
2. Return success
3. Asynchronously write to database
```

### Eviction Policies

**LRU (Least Recently Used)**:
```
maxmemory-policy allkeys-lru
```

**LFU (Least Frequently Used)**:
```
maxmemory-policy allkeys-lfu
```

**TTL-based**:
```
SET key value EX 3600  # Expires in 1 hour
```

## Real Code Examples

### Example: Session Store

```redis
# Store session
SET session:abc123 "user_id:456" EX 3600

# Get session
GET session:abc123

# Extend session
EXPIRE session:abc123 3600

# Delete session
DEL session:abc123
```

### Example: Rate Limiting

```redis
# Sliding window rate limiter
INCR rate_limit:user:123
EXPIRE rate_limit:user:123 60

# Check limit
GET rate_limit:user:123
# If > 100, rate limit exceeded
```

## Hard Use-Case: Distributed Cache

### Problem Statement

Implement a distributed cache with Redis Cluster for high availability.

### Solution

**Redis Cluster Setup**:
- Multiple Redis nodes
- Automatic sharding
- Failover support
- Data replication

**Client Configuration**:
```python
# Connect to cluster
from redis.cluster import RedisCluster

startup_nodes = [
    {"host": "127.0.0.1", "port": "7000"},
    {"host": "127.0.0.1", "port": "7001"},
]

rc = RedisCluster(startup_nodes=startup_nodes, decode_responses=True)
rc.set("key", "value")
```

## Edge Cases and Pitfalls

### Common Mistakes

1. **Cache Invalidation**
   - Invalidate on updates
   - Use TTL as backup
   - Consider cache versioning

2. **Cache Stampede**
   - Use locks for cache misses
   - Pre-warm cache
   - Use probabilistic expiration

3. **Memory Management**
   - Set maxmemory
   - Choose appropriate eviction policy
   - Monitor memory usage

## References and Further Reading

- Redis Official Documentation
- Redis Best Practices

## Quiz

### Question 1
What is the default eviction policy in Redis when maxmemory is reached?

**A)** noeviction  
**B)** allkeys-lru  
**C)** volatile-lru  
**D)** allkeys-random

**Answer: A** - The default is noeviction, which means Redis will return errors on write operations.

## Related Topics

- [Database Fundamentals](../01_beginners/03.%20Database%20Fundamentals.md)
- [Kafka Message Streaming](./04.%20Kafka%20Message%20Streaming.md)
- [Nginx Web Server Configuration](./05.%20Nginx%20Web%20Server%20Configuration.md)

