---
number: 20
title: "Rate Limiting Strategies"
slug: "rate-limiting-strategies"
level: "intermediate"
tags: ["backend", "rate-limiting", "throttling", "api-security", "performance"]
prerequisites: ["api-design-principles"]
estimated_minutes: 100
contributors: []
diagrams: []
examples: []
canonical_id: "backend-intermediate-20"
---

# Rate Limiting Strategies

## Overview

Rate limiting protects APIs from abuse and ensures fair resource usage. This guide covers rate limiting algorithms (token bucket, sliding window, fixed window), implementation strategies, distributed rate limiting, and best practices.

## Deep Explanation

### Algorithms

**Fixed Window**: Limit per time window
**Sliding Window**: Rolling time window
**Token Bucket**: Tokens refill at rate
**Leaky Bucket**: Requests leak at rate

### Rate Limit Headers

**X-RateLimit-Limit**: Request limit
**X-RateLimit-Remaining**: Remaining requests
**X-RateLimit-Reset**: Reset time

## Real Code Examples

### Example: Token Bucket Implementation

```python
import time
from collections import defaultdict

class TokenBucket:
    def __init__(self, capacity: int, refill_rate: float):
        self.capacity = capacity
        self.refill_rate = refill_rate  # tokens per second
        self.tokens = defaultdict(lambda: capacity)
        self.last_refill = defaultdict(time.time)
    
    def consume(self, key: str, tokens: int = 1) -> bool:
        now = time.time()
        elapsed = now - self.last_refill[key]
        
        # Refill tokens
        self.tokens[key] = min(
            self.capacity,
            self.tokens[key] + elapsed * self.refill_rate
        )
        self.last_refill[key] = now
        
        # Check if enough tokens
        if self.tokens[key] >= tokens:
            self.tokens[key] -= tokens
            return True
        return False

# Usage
rate_limiter = TokenBucket(capacity=100, refill_rate=10)  # 100 tokens, 10/sec

@app.get('/api/data')
def get_data(request: Request):
    client_ip = request.client.host
    if not rate_limiter.consume(client_ip):
        raise HTTPException(
            status_code=429,
            detail='Rate limit exceeded',
            headers={
                'X-RateLimit-Limit': '100',
                'X-RateLimit-Remaining': '0',
                'Retry-After': '60'
            }
        )
    return {'data': '...'}
```

### Example: Redis-Based Rate Limiting

```python
import redis

r = redis.Redis()

def rate_limit(key: str, limit: int, window: int) -> bool:
    """
    Sliding window rate limiting using Redis
    """
    now = time.time()
    pipeline = r.pipeline()
    
    # Remove old entries
    pipeline.zremrangebyscore(key, 0, now - window)
    
    # Count current requests
    pipeline.zcard(key)
    
    # Add current request
    pipeline.zadd(key, {str(now): now})
    
    # Set expiration
    pipeline.expire(key, window)
    
    results = pipeline.execute()
    count = results[1]
    
    if count < limit:
        return True
    return False

@app.get('/api/data')
def get_data(request: Request):
    client_ip = request.client.host
    if not rate_limit(f'rate_limit:{client_ip}', limit=100, window=60):
        raise HTTPException(status_code=429, detail='Rate limit exceeded')
    return {'data': '...'}
```

## Pros and Cons

### Pros

✅ **Protection**: Prevents abuse and DDoS
✅ **Fair Usage**: Ensures fair resource distribution
✅ **Cost Control**: Prevents unexpected costs
✅ **Stability**: Protects backend from overload
✅ **Flexible**: Multiple algorithms for different needs

### Cons

❌ **Complexity**: Requires careful implementation
❌ **False Positives**: May block legitimate users
❌ **Distributed**: Harder to implement across servers
❌ **Performance**: Adds overhead to requests
❌ **User Experience**: Can frustrate users if too strict

## Hard Use-Case: Multi-Tier Rate Limiting

### Problem Statement

Implement rate limiting with different limits for different user tiers (free, premium, enterprise).

### Solution

```python
class TieredRateLimiter:
    def __init__(self):
        self.limits = {
            'free': {'requests': 100, 'window': 3600},      # 100/hour
            'premium': {'requests': 1000, 'window': 3600},  # 1000/hour
            'enterprise': {'requests': 10000, 'window': 3600}  # 10000/hour
        }
        self.buckets = {}
    
    def check_limit(self, user_id: str, tier: str) -> bool:
        if tier not in self.limits:
            tier = 'free'
        
        limit_config = self.limits[tier]
        key = f'{user_id}:{tier}'
        
        if key not in self.buckets:
            self.buckets[key] = TokenBucket(
                capacity=limit_config['requests'],
                refill_rate=limit_config['requests'] / limit_config['window']
            )
        
        return self.buckets[key].consume(key)

# Usage
rate_limiter = TieredRateLimiter()

@app.get('/api/data')
def get_data(request: Request, user: User):
    if not rate_limiter.check_limit(user.id, user.tier):
        raise HTTPException(status_code=429, detail='Rate limit exceeded')
    return {'data': '...'}
```

## Edge Cases and Pitfalls

### Common Mistakes

1. **Not Using Distributed Rate Limiting**
   - Single server rate limiting doesn't work across load balancers
   - Use Redis or shared state
   - Consider consistent hashing

2. **Too Strict Limits**
   - Balance security with usability
   - Provide clear error messages
   - Include Retry-After header

3. **Not Handling Burst Traffic**
   - Use token bucket for bursts
   - Allow some burst capacity
   - Monitor and adjust limits

## References and Further Reading

- Rate Limiting Algorithms
- API Rate Limiting Best Practices

## Quiz

### Question 1
Which rate limiting algorithm allows burst traffic?

**A)** Fixed window  
**B)** Token bucket  
**C)** Sliding window  
**D)** Leaky bucket

**Answer: B** - Token bucket allows burst traffic up to bucket capacity.

## Related Topics

- [API Design Principles](../01_beginners/02.%20API%20Design%20Principles.md)
- [API Security Best Practices](../03_advanced/08.%20API%20Security%20Best%20Practices.md)

