---
number: 11
title: "AWS S3 Object Storage"
slug: "aws-s3-object-storage"
level: "intermediate"
tags: ["backend", "s3", "object-storage", "aws", "cloud-storage"]
prerequisites: ["backend-development-fundamentals"]
estimated_minutes: 110
contributors: []
diagrams: []
examples: []
canonical_id: "backend-intermediate-11"
---

# AWS S3 Object Storage

## Overview

Amazon S3 is an object storage service. This guide covers S3 buckets and objects, access control, versioning, lifecycle policies, encryption, performance optimization, and best practices for using S3 in backend applications.

## Deep Explanation

### Core Concepts

**Bucket**: Container for objects
**Object**: File and metadata
**Key**: Unique identifier
**Region**: Geographic location

### Storage Classes

**Standard**: General purpose
**Intelligent-Tiering**: Automatic cost optimization
**Standard-IA**: Infrequent access
**Glacier**: Archive storage

### Access Control

**IAM Policies**: User/role permissions
**Bucket Policies**: Bucket-level permissions
**ACLs**: Object-level permissions
**Pre-signed URLs**: Temporary access

## Real Code Examples

### Example: Upload File

```python
import boto3

s3 = boto3.client('s3')

# Upload file
s3.upload_file('local_file.txt', 'my-bucket', 'remote_file.txt')

# Upload with metadata
s3.upload_file(
    'local_file.txt',
    'my-bucket',
    'remote_file.txt',
    ExtraArgs={'Metadata': {'author': 'John'}}
)
```

### Example: Pre-signed URL

```python
# Generate pre-signed URL
url = s3.generate_presigned_url(
    'get_object',
    Params={'Bucket': 'my-bucket', 'Key': 'file.txt'},
    ExpiresIn=3600
)
```

## Hard Use-Case: Multi-Region Backup

### Problem Statement

Implement a backup strategy using S3 cross-region replication.

### Solution

**Enable Replication**:
```json
{
  "Rules": [{
    "Status": "Enabled",
    "Destination": {
      "Bucket": "arn:aws:s3:::backup-bucket",
      "StorageClass": "STANDARD_IA"
    }
  }]
}
```

**Lifecycle Policy**:
```json
{
  "Rules": [{
    "Id": "ArchiveOldFiles",
    "Status": "Enabled",
    "Transitions": [{
      "Days": 90,
      "StorageClass": "GLACIER"
    }]
  }]
}
```

## Edge Cases and Pitfalls

### Common Mistakes

1. **Public Access**
   - Disable public access by default
   - Use IAM policies
   - Audit bucket policies

2. **Not Using Lifecycle Policies**
   - Move old data to cheaper storage
   - Automate cleanup
   - Reduce costs

3. **Missing Versioning**
   - Enable versioning for critical data
   - Protect against accidental deletion
   - Maintain history

## References and Further Reading

- AWS S3 Documentation
- S3 Best Practices

## Quiz

### Question 1
What is the maximum object size in S3?

**A)** 5GB  
**B)** 5TB  
**C)** Unlimited  
**D)** 100GB

**Answer: B** - S3 supports objects up to 5TB in size.

## Related Topics

- [Backend Development Fundamentals](../01_beginners/01.%20Backend%20Development%20Fundamentals.md)
- [Google BigQuery Analytics](./12.%20Google%20BigQuery%20Analytics.md)

