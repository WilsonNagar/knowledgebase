---
number: 4
title: "Kafka Message Streaming"
slug: "kafka-message-streaming"
level: "intermediate"
tags: ["backend", "kafka", "messaging", "streaming", "event-driven"]
prerequisites: ["redis-caching-strategies"]
estimated_minutes: 130
contributors: []
diagrams: []
examples: []
canonical_id: "backend-intermediate-04"
---

# Kafka Message Streaming

## Overview

Apache Kafka is a distributed event streaming platform. This guide covers Kafka architecture, topics and partitions, producers and consumers, consumer groups, replication, Zookeeper coordination, and building event-driven architectures.

## Deep Explanation

### Core Concepts

**Topics**: Categories or feeds where records are published
**Partitions**: Topics are split into partitions for parallelism
**Producers**: Applications that publish data to topics
**Consumers**: Applications that read data from topics
**Brokers**: Kafka servers that store data

### Topic and Partition Model

```
Topic: user-events
├── Partition 0: [msg1, msg2, msg3]
├── Partition 1: [msg4, msg5, msg6]
└── Partition 2: [msg7, msg8, msg9]
```

**Partitioning Strategy**:
- Round-robin (default)
- Key-based (same key → same partition)
- Custom partitioner

### Producer Configuration

**Key Settings**:
- `acks`: 0, 1, or all (reliability)
- `retries`: Number of retries
- `batch.size`: Batch size for efficiency
- `linger.ms`: Wait time before sending batch

**Example**:
```properties
acks=all
retries=3
batch.size=16384
linger.ms=10
```

### Consumer Groups

**Consumer Group**: Multiple consumers working together
- Each partition consumed by one consumer in group
- Load balancing across consumers
- Parallel processing

**Offset Management**:
- Consumers track position (offset)
- Committed offsets for recovery
- Can reset to beginning or end

### Replication

**Replication Factor**: Number of copies
- Leader: Handles reads/writes
- Followers: Replicate data
- Automatic failover if leader fails

## Real Code Examples

### Example: Producer

```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
    key_serializer=lambda k: k.encode('utf-8') if k else None
)

# Send message
producer.send('user-events', 
    key='user123',
    value={'action': 'login', 'timestamp': '2024-01-01'}
)

producer.flush()
```

### Example: Consumer

```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'user-events',
    bootstrap_servers=['localhost:9092'],
    group_id='user-processors',
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

for message in consumer:
    print(f"Key: {message.key}, Value: {message.value}")
    # Process message
```

## Hard Use-Case: Event Sourcing with Kafka

### Problem Statement

Implement event sourcing where all state changes are stored as events.

### Solution

**Event Store**:
- All events in Kafka topics
- Replay events to rebuild state
- Event versioning and schema evolution

**Architecture**:
```
User Action → Event Producer → Kafka Topic
                                    ↓
                            Event Consumers
                                    ↓
                            State Builders → Read Models
```

**Benefits**:
- Complete audit trail
- Time travel debugging
- Rebuild state from events

## Edge Cases and Pitfalls

### Common Mistakes

1. **Not Handling Consumer Lag**
   - Monitor consumer lag
   - Scale consumers if needed
   - Optimize processing

2. **Wrong Partitioning**
   - Choose partition key carefully
   - Avoid hot partitions
   - Consider data distribution

3. **Ignoring Replication**
   - Use replication factor >= 3
   - Monitor ISR (In-Sync Replicas)
   - Handle broker failures

## References and Further Reading

- Kafka Official Documentation
- Kafka: The Definitive Guide

## Quiz

### Question 1
What is the purpose of consumer groups in Kafka?

**A)** To ensure message ordering  
**B)** To enable parallel processing and load balancing  
**C)** To guarantee message delivery  
**D)** To encrypt messages

**Answer: B** - Consumer groups enable parallel processing by distributing partitions across consumers.

## Related Topics

- [Redis Caching Strategies](./03.%20Redis%20Caching%20Strategies.md)
- [Zookeeper Coordination](./06.%20Zookeeper%20Coordination.md)
- [Event-Driven Architecture](../03_advanced/01.%20Event-Driven%20Architecture.md)

