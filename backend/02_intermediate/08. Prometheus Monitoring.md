---
number: 8
title: "Prometheus Monitoring"
slug: "prometheus-monitoring"
level: "intermediate"
tags: ["backend", "prometheus", "monitoring", "metrics", "observability"]
prerequisites: ["api-design-principles"]
estimated_minutes: 120
contributors: []
diagrams: []
examples: []
canonical_id: "backend-intermediate-08"
---

# Prometheus Monitoring

## Overview

Prometheus is a monitoring and alerting toolkit. This guide covers Prometheus architecture, metrics collection, PromQL query language, alerting rules, service discovery, exporters, and building comprehensive monitoring solutions.

## Deep Explanation

### Core Concepts

**Metrics**: Time-series data
**Labels**: Key-value pairs for filtering
**Scraping**: Pulling metrics from targets
**PromQL**: Query language for metrics

### Metric Types

**Counter**: Monotonically increasing value
```
http_requests_total{method="GET", status="200"} 1500
```

**Gauge**: Value that can go up or down
```
memory_usage_bytes{instance="server1"} 1024000
```

**Histogram**: Distribution of values
```
http_request_duration_seconds_bucket{le="0.1"} 100
```

**Summary**: Similar to histogram with quantiles

### PromQL Queries

**Select time series**:
```
http_requests_total{method="GET"}
```

**Rate calculation**:
```
rate(http_requests_total[5m])
```

**Aggregation**:
```
sum(http_requests_total) by (method)
```

**Functions**:
```
avg(rate(http_requests_total[5m]))
max(memory_usage_bytes)
```

## Real Code Examples

### Example: Instrumenting Application

```python
from prometheus_client import Counter, Histogram, start_http_server

# Define metrics
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')

# Instrument code
@REQUEST_DURATION.time()
def handle_request(method, endpoint):
    REQUEST_COUNT.labels(method=method, endpoint=endpoint).inc()
    # Process request
```

### Example: Alerting Rules

```yaml
groups:
  - name: api_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"
```

## Hard Use-Case: Multi-Service Monitoring

### Problem Statement

Monitor multiple microservices with Prometheus, aggregate metrics, and set up alerting.

### Solution

**Prometheus Configuration**:
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'api-service'
    static_configs:
      - targets: ['api1:8080', 'api2:8080']
    metrics_path: '/metrics'
  
  - job_name: 'database'
    static_configs:
      - targets: ['postgres-exporter:9187']
  
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
```

**Alerting Rules**:
```yaml
groups:
  - name: service_health
    rules:
      - alert: ServiceDown
        expr: up{job="api-service"} == 0
        for: 1m
      
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
```

## Edge Cases and Pitfalls

### Common Mistakes

1. **Cardinality Explosion**
   - Limit label combinations
   - Use recording rules
   - Monitor metric cardinality

2. **Missing Labels**
   - Include relevant labels
   - Consistent labeling
   - Document label meanings

3. **Not Setting Retention**
   - Configure retention policy
   - Use remote storage for long-term

## References and Further Reading

- Prometheus Official Documentation
- PromQL Best Practices

## Quiz

### Question 1
What is the default scrape interval in Prometheus?

**A)** 5 seconds  
**B)** 15 seconds  
**C)** 30 seconds  
**D)** 60 seconds

**Answer: B** - The default scrape interval is 15 seconds.

## Related Topics

- [Grafana Visualization](./09.%20Grafana%20Visualization.md)
- [New Relic APM](./10.%20New%20Relic%20APM.md)
- [Observability Best Practices](../03_advanced/04.%20Observability%20Best%20Practices.md)

