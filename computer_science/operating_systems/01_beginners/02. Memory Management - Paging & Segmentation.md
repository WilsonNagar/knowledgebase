---
number: 2
title: "Memory Management - Paging & Segmentation"
slug: "memory-management-paging-segmentation"
level: "fundamentals"
tags: ["operating-systems", "memory", "paging", "segmentation", "virtual-memory"]
prerequisites: []
estimated_minutes: 100
contributors: []
diagrams: []
examples: []
canonical_id: "cs-os-02"
---

# Memory Management - Paging & Segmentation

## Overview

Memory management is one of the most critical functions of an operating system. Understanding paging, segmentation, virtual memory, and how the OS manages physical and virtual address spaces is essential for system programming, performance optimization, and understanding how modern operating systems work.

## Table of Contents

1. [Memory Management Overview](#overview)
2. [Physical vs Virtual Memory](#physical-virtual)
3. [Paging](#paging)
4. [Segmentation](#segmentation)
5. [Combined Paging and Segmentation](#combined)
6. [Page Tables](#page-tables)
7. [Translation Lookaside Buffer (TLB)](#tlb)
8. [Page Replacement Algorithms](#page-replacement)
9. [Swapping](#swapping)

## Memory Management Overview

### The Problem

**Limited Physical Memory**:
- Physical RAM is finite
- Multiple processes need memory
- Processes may need more memory than available

**Requirements**:
- **Protection**: Processes shouldn't access each other's memory
- **Sharing**: Some memory can be shared (code, libraries)
- **Efficiency**: Minimize wasted memory
- **Abstraction**: Hide physical memory details from processes

### Memory Management Goals

**1. Address Space Isolation**:
- Each process has own address space
- Cannot access other processes' memory
- Security and stability

**2. Virtual Memory**:
- Processes see virtual address space
- OS maps virtual to physical addresses
- Can be larger than physical memory

**3. Efficient Utilization**:
- Minimize fragmentation
- Maximize memory usage
- Fast allocation/deallocation

## Physical vs Virtual Memory

### Physical Memory

**Physical Memory**: Actual RAM hardware

**Characteristics**:
- **Limited**: Fixed size (e.g., 8GB, 16GB)
- **Direct**: CPU can access directly
- **Shared**: All processes share same physical memory

**Addresses**: Physical addresses (e.g., 0x00000000 to 0x1FFFFFFF)

### Virtual Memory

**Virtual Memory**: Abstract address space seen by processes

**Characteristics**:
- **Unlimited**: Can be larger than physical memory
- **Per-process**: Each process has own virtual address space
- **Isolated**: Processes cannot see each other's virtual memory

**Addresses**: Virtual addresses (e.g., 0x00000000 to 0xFFFFFFFF for 32-bit)

### Address Translation

**Process**:
```
Virtual Address → Page Table → Physical Address
```

**Example**:
```
Process sees: Virtual address 0x1000
OS translates: To physical address 0x5000
CPU accesses: Physical address 0x5000
```

**Benefits**:
- **Isolation**: Processes use different virtual addresses
- **Flexibility**: Physical pages can be anywhere
- **Swapping**: Unused pages can be on disk

## Paging

### What is Paging?

**Paging**: Divide memory into fixed-size pages

**Key Concepts**:
- **Page**: Fixed-size block of virtual memory (typically 4KB)
- **Frame**: Fixed-size block of physical memory (same size as page)
- **Page Table**: Maps virtual pages to physical frames

### Paging Structure

**Virtual Address Structure** (32-bit, 4KB pages):
```
31        12 11        0
┌──────────┬──────────┐
│ Page #   │ Offset   │
│ (20 bits)│ (12 bits)│
└──────────┴──────────┘
```

**Translation Process**:
```
1. Extract page number from virtual address
2. Look up page number in page table
3. Get frame number
4. Combine frame number + offset = physical address
```

### Paging Example

**Virtual Address**: 0x12345678

**Breakdown**:
- Page number: 0x12345 (20 bits)
- Offset: 0x678 (12 bits)

**Translation**:
```
Page Table Entry for page 0x12345:
  Frame: 0x5000
  Flags: Present, Read/Write

Physical Address = (0x5000 << 12) | 0x678
                 = 0x5000678
```

### Page Table Entry (PTE)

**Structure** (32-bit example):
```
31    12 11  9 8 7 6 5 4 3 2 1 0
┌──────┬───┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐
│Frame │Res│ │ │ │ │ │ │ │ │ │ │
│Number│erv│ │ │ │ │ │ │ │ │ │ │
└──────┴───┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘
        │   │ │ │ │ │ │ │ │ │ │
        │   │ │ │ │ │ │ │ │ │ └─ Present
        │   │ │ │ │ │ │ │ │ └─── Read/Write
        │   │ │ │ │ │ │ │ └───── User/Supervisor
        │   │ │ │ │ │ │ └─────── Write-Through
        │   │ │ │ │ │ └───────── Cache Disabled
        │   │ │ │ │ └─────────── Accessed
        │   │ │ │ └───────────── Dirty
        │   │ │ └─────────────── Page Size
        │   │ └───────────────── Global
        │   └─────────────────── Available
        └─────────────────────── Frame Number
```

**Key Flags**:
- **Present**: Page in physical memory
- **Read/Write**: Read-only or writable
- **User/Supervisor**: User or kernel access
- **Accessed**: Page recently accessed
- **Dirty**: Page modified

### Paging Advantages

**1. No External Fragmentation**:
- Pages are fixed size
- Any frame can hold any page
- No wasted space between allocations

**2. Simple Allocation**:
- Allocate frames from free list
- No complex allocation algorithms needed

**3. Easy Swapping**:
- Pages can be swapped to disk
- Load pages back when needed

**4. Sharing**:
- Multiple processes can share same frame
- Useful for code, libraries

### Paging Disadvantages

**1. Internal Fragmentation**:
- Process may not use full page
- Wasted space within page
- Average waste: half page per process

**2. Page Table Overhead**:
- Large address spaces need large page tables
- Memory overhead for page tables
- Multi-level page tables help

**3. Translation Overhead**:
- Every memory access needs translation
- TLB helps but adds complexity

## Segmentation

### What is Segmentation?

**Segmentation**: Divide memory into variable-size segments

**Key Concepts**:
- **Segment**: Logical unit (code, data, stack, heap)
- **Segment Table**: Maps segment number to base address
- **Variable Size**: Segments can be different sizes

### Segmentation Structure

**Virtual Address Structure**:
```
31        16 15        0
┌──────────┬──────────┐
│ Segment  │ Offset   │
│ Number   │          │
└──────────┴──────────┘
```

**Translation Process**:
```
1. Extract segment number from virtual address
2. Look up segment in segment table
3. Get base address and limit
4. Check offset < limit
5. Physical address = base + offset
```

### Segment Table Entry

**Structure**:
```
┌─────────────┬─────────────┬──────────┐
│ Base Address│    Limit    │  Flags   │
│  (32 bits)  │  (32 bits)  │          │
└─────────────┴─────────────┴──────────┘
```

**Flags**:
- **Present**: Segment in memory
- **Read/Write**: Permissions
- **Grows Up/Down**: Stack grows down

### Segmentation Example

**Process Address Space**:
```
Segment 0: Code (0x00000000 - 0x0000FFFF)
Segment 1: Data (0x00010000 - 0x0001FFFF)
Segment 2: Stack (0xFFFF0000 - 0xFFFFFFFF)
```

**Virtual Address**: 0x00012345

**Breakdown**:
- Segment: 0x0001
- Offset: 0x2345

**Translation**:
```
Segment Table Entry for segment 1:
  Base: 0x10000000
  Limit: 0x10000
  Present: Yes

Physical Address = 0x10000000 + 0x2345
                 = 0x10002345
```

### Segmentation Advantages

**1. Logical Organization**:
- Matches program structure
- Code, data, stack separate
- Easy to understand

**2. Protection**:
- Different permissions per segment
- Code: read-only
- Data: read/write
- Stack: read/write, grows down

**3. Sharing**:
- Share code segments
- Private data segments
- Efficient memory use

**4. No Internal Fragmentation**:
- Segments are exact size needed
- No wasted space within segment

### Segmentation Disadvantages

**1. External Fragmentation**:
- Variable-size segments
- Memory becomes fragmented
- Need compaction or complex allocation

**2. Complex Allocation**:
- Must find contiguous space
- Allocation algorithms more complex
- Slower allocation

**3. Swapping Difficult**:
- Entire segment must be swapped
- Large segments problematic

## Combined Paging and Segmentation

### Why Combine?

**Best of Both Worlds**:
- **Segmentation**: Logical organization, protection
- **Paging**: No external fragmentation, easy swapping

**How It Works**:
```
Virtual Address:
  Segment Number → Segment Table → Page Table → Physical Frame
```

### Combined Address Translation

**Address Structure**:
```
31    16 15    12 11       0
┌──────┬──────┬──────────┐
│ Seg  │ Page │  Offset  │
│ Num  │ Num  │          │
└──────┴──────┴──────────┘
```

**Translation Steps**:
```
1. Extract segment number
2. Look up segment table → Get page table base
3. Extract page number
4. Look up page table → Get frame number
5. Combine frame + offset = physical address
```

### Benefits

**1. Logical Organization**:
- Segments organize code/data/stack
- Each segment has own page table

**2. Efficient Memory Use**:
- Paging eliminates external fragmentation
- Segments can be any size (multiple pages)

**3. Protection**:
- Segment-level protection
- Page-level protection
- Fine-grained control

**4. Swapping**:
- Swap individual pages
- Not entire segments
- More efficient

## Page Tables

### Single-Level Page Table

**Structure**:
```
Page Table (Array)
Index: Page number
Value: Frame number + flags
```

**Size Calculation** (32-bit, 4KB pages):
```
Virtual address space: 2^32 = 4GB
Page size: 4KB = 2^12
Number of pages: 2^32 / 2^12 = 2^20 = 1M pages
Page table entries: 1M entries
Entry size: 4 bytes
Total size: 4MB per process
```

**Problem**: Too large for many processes

### Multi-Level Page Tables

**Two-Level Page Table**:
```
Virtual Address:
  ┌──────────┬──────────┬──────────┐
  │ Page Dir │ Page Tab │  Offset  │
  │ (10 bits)│ (10 bits)│ (12 bits)│
  └──────────┴──────────┴──────────┘
```

**Translation**:
```
1. Extract page directory index
2. Look up page directory → Get page table address
3. Extract page table index
4. Look up page table → Get frame number
5. Combine frame + offset
```

**Size Calculation**:
```
Page directory: 2^10 = 1024 entries × 4 bytes = 4KB
Page tables: Only for used pages
Total: Much smaller than single-level
```

**Benefits**:
- **Sparse**: Only allocate page tables for used pages
- **Smaller**: Much less memory overhead
- **Efficient**: Fast lookup

### Inverted Page Tables

**Concept**: One page table for all processes

**Structure**:
```
Index: Physical frame number
Value: Virtual page + process ID
```

**Benefits**:
- **Small**: One table for all processes
- **Efficient**: Fixed size

**Drawbacks**:
- **Slow**: Must search table
- **Complex**: Hash tables needed

## Translation Lookaside Buffer (TLB)

### What is TLB?

**TLB**: Hardware cache for page table entries

**Purpose**: Speed up address translation

**Location**: CPU (hardware)

**Size**: Typically 64-512 entries

### TLB Operation

**Translation Flow**:
```
1. Check TLB for virtual page
2. If found (TLB hit): Use cached frame number
3. If not found (TLB miss): Look up page table
4. Update TLB with new entry
5. Use frame number
```

**TLB Hit Rate**: Typically 95-99%

**Performance Impact**:
- **TLB hit**: 1 cycle (very fast)
- **TLB miss**: 10-100 cycles (page table walk)

### TLB Management

**TLB Flush**:
- **Context switch**: Flush TLB (new process)
- **Page table update**: Invalidate entries
- **ASLR**: Randomize addresses, flush TLB

**TLB Shootdown**:
- **Multi-core**: Invalidate TLB on other CPUs
- **Synchronization**: Ensure consistency
- **Cost**: Expensive operation

## Page Replacement Algorithms

### The Problem

**Page Fault**: Page not in physical memory

**Solution**: Replace existing page

**Goal**: Minimize page faults

### Optimal Algorithm (OPT)

**Strategy**: Replace page used farthest in future

**Example**:
```
Pages: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
Frames: 3

1: [1] (fault)
2: [1,2] (fault)
3: [1,2,3] (fault)
4: [1,2,4] (fault, replace 3 - used at 7)
1: [1,2,4] (hit)
2: [1,2,4] (hit)
5: [1,2,5] (fault, replace 4 - used at 11)
...
```

**Problem**: Requires future knowledge (unrealistic)

**Use**: Benchmark for other algorithms

### First-In-First-Out (FIFO)

**Strategy**: Replace oldest page

**Example**:
```
Pages: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
Frames: 3

1: [1] (fault)
2: [1,2] (fault)
3: [1,2,3] (fault)
4: [4,2,3] (fault, replace 1)
1: [4,1,3] (fault, replace 2)
...
```

**Problem**: Belady's Anomaly (more frames can cause more faults)

### Least Recently Used (LRU)

**Strategy**: Replace least recently used page

**Example**:
```
Pages: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
Frames: 3

1: [1] (fault)
2: [1,2] (fault)
3: [1,2,3] (fault)
4: [4,2,3] (fault, replace 1 - LRU)
1: [4,1,3] (fault, replace 2 - LRU)
...
```

**Implementation**:
- **Hardware**: Use accessed bit, approximate LRU
- **Software**: Track access times, expensive

**Good Performance**: Close to optimal

### Clock Algorithm (Second Chance)

**Strategy**: FIFO with second chance

**How It Works**:
- Circular list of pages
- Clock hand points to candidate
- If accessed bit set: Clear bit, move hand
- If accessed bit clear: Replace page

**Benefits**:
- **Simple**: Easy to implement
- **Efficient**: O(1) per operation
- **Good**: Approximates LRU

## Swapping

### What is Swapping?

**Swapping**: Moving pages to disk when memory full

**Swap Space**: Disk area for swapped pages

**Process**:
```
1. Page fault occurs
2. No free frames available
3. Select victim page (LRU, etc.)
4. Write victim to swap space
5. Read needed page from swap
6. Update page table
7. Continue execution
```

### Swap Performance

**Costs**:
- **Disk I/O**: Slow (milliseconds vs nanoseconds)
- **Context switch**: Process blocked during swap
- **Overhead**: Significant performance impact

**Optimization**:
- **Pre-fetching**: Load pages before needed
- **Clustering**: Swap multiple pages together
- **SSD**: Faster than HDD

### Swap Space Management

**Swap File**: File on filesystem

**Swap Partition**: Dedicated disk partition

**Size**: Typically 1-2x RAM size

**Modern Systems**: May not use swap (sufficient RAM)

## Real-World Considerations

### Modern Memory Management

**64-bit Systems**:
- **Huge address space**: 2^64 addresses
- **Sparse page tables**: Most pages unused
- **Multi-level**: 4-5 level page tables

**Large Pages**:
- **2MB or 1GB pages**: Reduce TLB misses
- **Use case**: Large allocations (databases)

**NUMA (Non-Uniform Memory Access)**:
- **Multiple memory nodes**: Different access times
- **NUMA-aware**: Allocate pages from local node
- **Performance**: Significant impact

## Common Pitfalls

### Problem: Thrashing

**Scenario**:
```
Too many processes
Not enough physical memory
Constant page faults
System spends time swapping
Little useful work done
```

**Solution**:
- Reduce number of processes
- Add more RAM
- Improve locality
- Use larger pages

### Problem: TLB Misses

**Scenario**:
```
Large working set
Small TLB
Many TLB misses
Slow performance
```

**Solution**:
- Use larger pages (2MB, 1GB)
- Improve locality
- Larger TLB (hardware)
- TLB-aware algorithms

## Quiz

1. What is the main advantage of paging over segmentation?
   - **A)** Logical organization
   - **B)** No external fragmentation
   - **C)** Variable size
   - **D)** Simpler implementation

2. What does TLB cache?
   - **A)** Virtual addresses
   - **B)** Page table entries
   - **C)** Physical addresses
   - **D)** Process IDs

3. What is the goal of page replacement algorithms?
   - **A)** Maximize memory usage
   - **B)** Minimize page faults
   - **C)** Maximize TLB hits
   - **D)** Minimize swap space

**Answers:**
1. **B** - Paging eliminates external fragmentation because pages are fixed size, so any frame can hold any page
2. **B** - TLB caches page table entries (virtual page to physical frame mappings) to speed up address translation
3. **B** - Page replacement algorithms aim to minimize page faults by choosing good victim pages to replace

## Next Steps

- [Virtual Memory Internals & TLB](./03.%20Virtual%20Memory%20Internals%20%26%20TLB.md) - Deep dive into virtual memory
- [CPU Scheduling Fundamentals](./01.%20CPU%20Scheduling%20Fundamentals.md) - Process scheduling

