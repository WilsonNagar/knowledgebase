---
number: 9
title: "I/O Subsystems - Block Devices & DMA"
slug: "io-subsystems-block-devices-dma"
level: "intermediate"
tags: ["operating-systems", "io", "block-devices", "dma", "storage"]
prerequisites: ["interrupts-traps"]
estimated_minutes: 105
contributors: []
diagrams: []
examples: []
canonical_id: "cs-os-09"
---

# I/O Subsystems - Block Devices & DMA

## Overview

I/O subsystems handle communication between CPU and storage devices. Understanding block devices, DMA (Direct Memory Access), I/O scheduling, and buffering is essential for system programming, performance optimization, and understanding how operating systems manage storage.

## Table of Contents

1. [I/O Overview](#io-overview)
2. [Block Devices](#block-devices)
3. [Direct Memory Access (DMA)](#dma)
4. [I/O Scheduling](#io-scheduling)
5. [Buffering](#buffering)
6. [I/O Modes](#io-modes)
7. [Performance Optimization](#performance)

## I/O Overview

### Types of I/O Devices

**1. Block Devices**:
- **Characteristics**: Fixed-size blocks
- **Examples**: Hard drives, SSDs
- **Access**: Random access
- **Unit**: Blocks (typically 512B-4KB)

**2. Character Devices**:
- **Characteristics**: Stream of bytes
- **Examples**: Keyboard, mouse, serial ports
- **Access**: Sequential
- **Unit**: Bytes

**3. Network Devices**:
- **Characteristics**: Packets
- **Examples**: Network cards
- **Access**: Packet-based
- **Unit**: Packets

## Block Devices

### What are Block Devices?

**Block Device**: Storage device accessed in fixed-size blocks

**Characteristics**:
- **Blocks**: Fixed-size units (512B, 4KB)
- **Random access**: Can access any block
- **Persistent**: Data survives power loss

### Block Device Structure

**Organization**:
```
Block Device:
  Block 0: Boot sector
  Block 1-N: File system data
  Block N+1-M: User data
```

**Block Addressing**:
- **LBA**: Logical Block Address
- **Addressing**: Block number (0, 1, 2, ...)
- **Size**: Typically 512 bytes or 4KB

### Block Device Operations

**Read Block**:
```
Request: Read block N
Process:
  1. Seek to block N (if needed)
  2. Read block data
  3. Transfer to memory
  4. Return data
```

**Write Block**:
```
Request: Write block N
Process:
  1. Seek to block N (if needed)
  2. Transfer data from memory
  3. Write block data
  4. Return status
```

### Block Device Performance

**Latency Components**:
- **Seek time**: Move head to track (HDD: ~5-10ms)
- **Rotational delay**: Wait for sector (HDD: ~4ms average)
- **Transfer time**: Read/write data (~0.1ms per block)

**SSD**: No seek/rotation, much faster

## Direct Memory Access (DMA)

### The Problem

**Programmed I/O (PIO)**:
```
CPU reads byte from device
CPU writes byte to memory
CPU reads next byte
CPU writes next byte
...
CPU busy during entire transfer
```

**Problem**: CPU tied up during I/O

### DMA Solution

**DMA**: Direct Memory Access

**How It Works**:
```
1. CPU sets up DMA transfer:
   - Source: Device buffer
   - Destination: Memory address
   - Size: Number of bytes
2. DMA controller handles transfer
3. CPU continues other work
4. DMA interrupts when done
```

**Benefits**:
- **CPU free**: CPU can do other work
- **Parallel**: Transfer and computation overlap
- **Efficient**: Better utilization

### DMA Process

**Step 1: Setup**:
```c
// CPU programs DMA controller
dma_setup(source_addr, dest_addr, size);
```

**Step 2: Transfer**:
```
DMA controller:
  1. Reads from source
  2. Writes to destination
  3. Increments addresses
  4. Decrements counter
  5. Repeats until done
```

**Step 3: Completion**:
```
DMA controller generates interrupt
CPU handles interrupt
Transfer complete
```

### DMA Modes

**1. Single Transfer**:
- **One byte**: Per DMA request
- **Use**: Slow devices

**2. Block Transfer**:
- **Entire block**: One DMA request
- **Use**: Fast devices

**3. Burst Transfer**:
- **Multiple blocks**: Continuous transfer
- **Use**: High-speed devices

## I/O Scheduling

### The Problem

**Random I/O**: Inefficient

**Example**:
```
Request 1: Block 1000
Request 2: Block 50
Request 3: Block 2000
Request 4: Block 100
```

**Problem**: Head movement inefficient (HDD)

### I/O Scheduler

**Purpose**: Reorder requests for efficiency

**Goals**:
- **Minimize seek time**: Group nearby requests
- **Fairness**: Prevent starvation
- **Throughput**: Maximize I/O rate

### Scheduling Algorithms

**1. FIFO**:
- **Simple**: First come, first served
- **Problem**: No optimization

**2. Shortest Seek First (SSF)**:
- **Idea**: Serve nearest request first
- **Problem**: Starvation possible

**3. SCAN (Elevator)**:
- **Idea**: Move head in one direction
- **Process**: All requests in that direction
- **Turn around**: At end, reverse direction
- **Fair**: No starvation

**4. C-SCAN**:
- **Idea**: Always scan in one direction
- **Return**: Quickly to start
- **Fair**: Uniform wait time

**5. Deadline Scheduler** (Linux):
- **Idea**: Ensure requests meet deadlines
- **Read deadline**: 500ms
- **Write deadline**: 5s
- **Prevents**: Starvation

### Linux I/O Schedulers

**1. Noop**:
- **Simple**: FIFO queue
- **Use**: SSDs (no seek optimization needed)

**2. Deadline**:
- **Deadlines**: Read/write deadlines
- **Use**: General purpose

**3. CFQ** (Completely Fair Queuing):
- **Fair**: Per-process queues
- **Use**: Desktop systems

**4. BFQ** (Budget Fair Queuing):
- **Fair**: Better fairness
- **Use**: Interactive systems

## Buffering

### Why Buffer?

**Problem**: Speed mismatch

**CPU**: Nanoseconds
**Memory**: Nanoseconds
**Disk**: Milliseconds

**Solution**: Buffer in memory

### Buffer Cache

**Purpose**: Cache frequently accessed blocks

**Structure**:
```
Buffer Cache:
  Block 100 → [data in memory]
  Block 200 → [data in memory]
  Block 300 → [data in memory]
```

**Benefits**:
- **Fast access**: Memory faster than disk
- **Reduce I/O**: Fewer disk accesses
- **Performance**: Significant improvement

### Write-Back vs Write-Through

**Write-Through**:
```
Write to cache
Write to disk immediately
Simple, but slower
```

**Write-Back**:
```
Write to cache only
Write to disk later (lazy)
Faster, but risk of data loss
```

**Trade-off**: Performance vs durability

## I/O Modes

### Synchronous I/O

**Blocking**:
```c
read(fd, buffer, size); // Blocks until data ready
// Continue after read completes
```

**Characteristics**:
- **Simple**: Easy to program
- **Blocking**: Thread waits
- **Use**: Most applications

### Asynchronous I/O

**Non-Blocking**:
```c
aio_read(fd, buffer, size); // Returns immediately
// Check later if data ready
```

**Characteristics**:
- **Complex**: More complex programming
- **Non-blocking**: Thread continues
- **Use**: High-performance applications

### I/O Multiplexing

**select/poll/epoll**:
```c
// Wait for multiple file descriptors
select(nfds, readfds, writefds, NULL, timeout);
// Returns when any ready
```

**Benefits**:
- **Efficient**: One thread handles multiple I/O
- **Scalable**: Better than one thread per I/O

## Performance Optimization

### Reducing I/O

**1. Caching**:
```
Cache frequently accessed data
Reduce disk I/O
```

**2. Prefetching**:
```
Read data before needed
Hide latency
```

**3. Batching**:
```
Group multiple operations
Single I/O for multiple operations
```

### Optimizing I/O Patterns

**1. Sequential Access**:
```
Read blocks sequentially
Better than random access
```

**2. Alignment**:
```
Align I/O to block boundaries
Avoid partial block reads
```

**3. Large Transfers**:
```
Read/write large chunks
Better throughput
```

## Real-World Examples

### Example 1: File Read

**Process**:
```
1. Application: read(file, buffer, size)
2. File system: Translate to block numbers
3. Buffer cache: Check if blocks cached
4. If cached: Return from cache
5. If not: Schedule I/O request
6. I/O scheduler: Reorder requests
7. Block device: Read blocks
8. DMA: Transfer to memory
9. Buffer cache: Cache blocks
10. Return: Data to application
```

### Example 2: Database Write

**Process**:
```
1. Database: Update row
2. Buffer pool: Modify page in memory
3. WAL: Write log record
4. Commit: Flush log (fsync)
5. Background: Write dirty pages
6. I/O scheduler: Optimize page writes
7. Block device: Write pages
8. DMA: Transfer from memory
```

## Common Pitfalls

### Problem: Ignoring I/O Scheduling

```c
// BAD: Random I/O pattern
for (int i = 0; i < n; i++) {
    read_block(random_block[i]); // Inefficient
}

// GOOD: Sequential or batched
for (int i = 0; i < n; i++) {
    read_block(i); // Sequential
}
```

### Problem: Small I/O Operations

```c
// BAD: Many small reads
for (int i = 0; i < 1000; i++) {
    read(fd, &byte, 1); // 1000 system calls
}

// GOOD: Large reads
read(fd, buffer, 1000); // 1 system call
```

## Quiz

1. What is the main advantage of DMA?
   - **A)** Faster CPU
   - **B)** Frees CPU to do other work while data transfers
   - **C)** More memory
   - **D)** Simpler code

2. What is the purpose of I/O scheduling?
   - **A)** Encrypt I/O
   - **B)** Reorder requests to minimize seek time and improve efficiency
   - **C)** Slow down I/O
   - **D)** Randomize I/O

3. What is a block device?
   - **A)** Network device
   - **B)** Storage device accessed in fixed-size blocks
   - **C)** Character device
   - **D)** CPU device

**Answers:**
1. **B** - DMA allows data transfers to happen without CPU involvement, freeing the CPU to perform other tasks while the transfer occurs
2. **B** - I/O scheduling reorders I/O requests to minimize disk head movement (seek time) and improve overall I/O efficiency and throughput
3. **B** - A block device is a storage device (like hard drives or SSDs) that is accessed in fixed-size blocks rather than as a stream of bytes

## Next Steps

- [File System Internals](./10.%20File%20System%20Internals.md) - File system implementation
- [Boot Process](./11.%20Boot%20Process.md) - System boot

