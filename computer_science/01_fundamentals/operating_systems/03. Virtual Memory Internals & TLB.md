---
number: 3
title: "Virtual Memory Internals & TLB"
slug: "virtual-memory-internals-tlb"
level: "fundamentals"
tags: ["operating-systems", "virtual-memory", "tlb", "memory-management", "paging"]
prerequisites: ["memory-management-paging-segmentation"]
estimated_minutes: 110
contributors: []
diagrams: []
examples: []
canonical_id: "cs-os-03"
---

# Virtual Memory Internals & TLB

## Overview

Virtual memory is one of the most important abstractions in modern operating systems. Understanding how virtual addresses are translated to physical addresses, how the Translation Lookaside Buffer (TLB) accelerates this process, and the internals of page tables is essential for system programming and performance optimization.

## Table of Contents

1. [Virtual Memory Overview](#overview)
2. [Address Translation Process](#address-translation)
3. [Page Table Structures](#page-tables)
4. [Translation Lookaside Buffer (TLB)](#tlb)
5. [TLB Management](#tlb-management)
6. [Page Fault Handling](#page-faults)
7. [Memory Protection](#memory-protection)
8. [Performance Considerations](#performance)

## Virtual Memory Overview

### Why Virtual Memory?

**Problems Solved**:
- **Protection**: Processes isolated from each other
- **Abstraction**: Processes see linear address space
- **Swapping**: Can use disk as extension of RAM
- **Sharing**: Multiple processes can share code/data

### Virtual Address Space

**32-bit Process**:
```
0x00000000 ────────────────────┐
                               │
        Program Code           │
                               │
        Program Data           │
                               │
        Heap (grows up)        │
                               │
        (unused)               │
                               │
        Stack (grows down)     │
                               │
0xFFFFFFFF ────────────────────┘
```

**64-bit Process**:
```
0x0000000000000000 ───────────┐
                               │
        Program Code           │
                               │
        Program Data           │
                               │
        Heap (grows up)        │
                               │
        (huge unused space)    │
                               │
        Stack (grows down)     │
                               │
0x7FFFFFFFFFFF ───────────────┘
```

### Benefits

**1. Process Isolation**:
- Each process has own virtual address space
- Process A's 0x1000 ≠ Process B's 0x1000
- Cannot access other processes' memory

**2. Simplified Memory Management**:
- Processes don't need to manage physical memory
- OS handles allocation and mapping
- Processes see simple linear address space

**3. Memory Overcommitment**:
- Can allocate more virtual memory than physical
- Unused pages swapped to disk
- More processes can run simultaneously

## Address Translation Process

### Basic Translation

**Virtual Address → Physical Address**:
```
Virtual Address: 0x12345678
    ↓
Extract Page Number: 0x12345
    ↓
Look up in Page Table
    ↓
Get Frame Number: 0x5000
    ↓
Combine Frame + Offset: 0x5000678
    ↓
Physical Address: 0x5000678
```

### Address Breakdown

**32-bit Address, 4KB Pages**:
```
31        12 11        0
┌──────────┬──────────┐
│ Page #   │ Offset   │
│ (20 bits)│ (12 bits)│
└──────────┴──────────┘

Page Number: 0x12345 (which page)
Offset: 0x678 (byte within page)
```

**Translation Steps**:
1. Extract page number from virtual address
2. Look up page number in page table
3. Get frame number from page table entry
4. Combine frame number with offset
5. Result is physical address

### Page Table Entry (PTE)

**Structure** (32-bit example):
```
31    12 11  9 8 7 6 5 4 3 2 1 0
┌──────┬───┬─┬─┬─┬─┬─┬─┬─┬─┬─┬─┐
│Frame │Res│ │ │ │ │ │ │ │ │ │ │
│Number│erv│ │ │ │ │ │ │ │ │ │ │
└──────┴───┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┘
        │   │ │ │ │ │ │ │ │ │ │ │
        │   │ │ │ │ │ │ │ │ │ └─ Present (P)
        │   │ │ │ │ │ │ │ │ └─── Read/Write (R/W)
        │   │ │ │ │ │ │ │ └───── User/Supervisor (U/S)
        │   │ │ │ │ │ │ └─────── Write-Through (PWT)
        │   │ │ │ │ │ └───────── Cache Disabled (PCD)
        │   │ │ │ │ └─────────── Accessed (A)
        │   │ │ │ └───────────── Dirty (D)
        │   │ │ └─────────────── Page Size (PS)
        │   │ └───────────────── Global (G)
        │   └─────────────────── Available
        └─────────────────────── Frame Number (20 bits)
```

**Key Flags**:
- **Present (P)**: Page in physical memory
- **Read/Write (R/W)**: Read-only or writable
- **User/Supervisor (U/S)**: User or kernel access
- **Accessed (A)**: Page recently accessed
- **Dirty (D)**: Page modified

## Page Table Structures

### Single-Level Page Table

**Structure**: Simple array

**Size Calculation** (32-bit, 4KB pages):
```
Virtual address space: 2^32 = 4GB
Page size: 4KB = 2^12 bytes
Number of pages: 2^32 / 2^12 = 2^20 = 1,048,576 pages
Page table entries: 1M entries
Entry size: 4 bytes
Total size: 4MB per process
```

**Problem**: Too large for many processes

**Example**:
```
Page Table:
Index 0:   Frame 0x1000, Present=1
Index 1:   Frame 0x2000, Present=1
Index 2:   Present=0 (not in memory)
...
Index 0x12345: Frame 0x5000, Present=1
```

### Multi-Level Page Tables

**Two-Level Page Table**:
```
Virtual Address:
  ┌──────────┬──────────┬──────────┐
  │ Page Dir │ Page Tab │  Offset  │
  │ (10 bits)│ (10 bits)│ (12 bits)│
  └──────────┴──────────┴──────────┘
```

**Translation**:
```
1. Extract page directory index (bits 22-31)
2. Look up page directory → Get page table address
3. Extract page table index (bits 12-21)
4. Look up page table → Get frame number
5. Combine frame number + offset (bits 0-11)
```

**Size Calculation**:
```
Page directory: 2^10 = 1024 entries × 4 bytes = 4KB
Page tables: Only allocate for used pages
  - If process uses 100 pages: 100 × 4KB = 400KB
Total: 4KB + 400KB = 404KB (vs 4MB single-level)
```

**Benefits**:
- **Sparse**: Only allocate for used pages
- **Smaller**: Much less memory overhead
- **Efficient**: Fast lookup (2 memory accesses)

### Three-Level Page Tables (64-bit)

**64-bit Address Structure**:
```
63    48 47    39 38    30 29    21 20    12 11        0
┌──────┬──────┬──────┬──────┬──────┬──────────────────┐
│ Sign │ PML4 │ PDPT │  PD  │  PT  │     Offset       │
│ Ext  │      │      │      │      │                  │
└──────┴──────┴──────┴──────┴──────┴──────────────────┘
```

**Translation**:
```
1. PML4 (Page Map Level 4) → PDPT address
2. PDPT (Page Directory Pointer Table) → PD address
3. PD (Page Directory) → PT address
4. PT (Page Table) → Frame number
5. Frame + Offset = Physical address
```

**Why Multiple Levels?**:
- **Huge address space**: 2^64 addresses
- **Sparse usage**: Most addresses unused
- **Efficient**: Only allocate what's needed

## Translation Lookaside Buffer (TLB)

### What is TLB?

**TLB**: Hardware cache for page table entries

**Purpose**: Speed up address translation

**Location**: CPU (hardware, on-chip)

**Size**: Typically 64-512 entries

**Speed**: 1 cycle (vs 10-100 cycles for page table walk)

### TLB Operation

**Translation Flow**:
```
1. CPU generates virtual address
2. Check TLB for virtual page
3. If TLB hit: Use cached frame number (fast!)
4. If TLB miss: Page table walk (slow)
5. Update TLB with new entry
6. Use frame number
```

**TLB Hit Rate**: Typically 95-99%

**Performance Impact**:
- **TLB hit**: 1 cycle (very fast)
- **TLB miss**: 10-100 cycles (page table walk)
- **Critical**: TLB performance crucial for overall performance

### TLB Structure

**Fully Associative TLB**:
```
Entry 0: VPN → Frame, Flags
Entry 1: VPN → Frame, Flags
...
Entry N: VPN → Frame, Flags

Search: Check all entries (parallel)
Fast but expensive hardware
```

**Set-Associative TLB**:
```
Set 0: [Entry 0, Entry 1, ..., Entry M]
Set 1: [Entry 0, Entry 1, ..., Entry M]
...
Set N: [Entry 0, Entry 1, ..., Entry M]

Search: Check one set (based on VPN hash)
Good balance of speed and cost
```

**Direct-Mapped TLB**:
```
Entry 0: VPN → Frame
Entry 1: VPN → Frame
...
Entry N: VPN → Frame

Search: Check one entry (VPN mod N)
Fastest but most conflicts
```

### TLB Entry Format

**Typical TLB Entry**:
```
┌─────────────┬─────────────┬──────────┐
│ Virtual Page│ Physical    │  Flags   │
│ Number      │ Frame       │          │
│ (VPN)       │ Number      │          │
└─────────────┴─────────────┴──────────┘
```

**Flags**: Present, Read/Write, User/Supervisor, etc.

## TLB Management

### TLB Flush

**When to Flush**:
- **Context switch**: New process has different page table
- **Page table update**: Invalidate stale entries
- **ASLR**: Address Space Layout Randomization changes mappings

**Full TLB Flush**:
```
On context switch:
1. Save current TLB state (if needed)
2. Flush all TLB entries
3. Load new process
4. TLB fills as process accesses memory
```

**Selective TLB Invalidation**:
```
On page table update:
1. Invalidate specific TLB entry
2. Other entries remain valid
3. More efficient than full flush
```

### TLB Shootdown

**Problem**: Multi-core systems

**Scenario**:
```
CPU 0: Updates page table
CPU 1: Has stale TLB entry
CPU 2: Has stale TLB entry
```

**Solution**: TLB Shootdown
```
1. CPU 0 updates page table
2. CPU 0 sends interrupt to other CPUs
3. Other CPUs invalidate TLB entries
4. All CPUs have consistent view
```

**Cost**: Expensive (inter-processor interrupts)

**Optimization**: Avoid when possible
- Use per-CPU page tables
- Use larger pages (fewer entries to invalidate)

### TLB Coherency

**Problem**: TLB and page table must be consistent

**Requirements**:
- TLB entry matches page table entry
- Updates to page table reflected in TLB
- No stale entries

**Mechanisms**:
- **Hardware**: Automatic invalidation on page table write
- **Software**: Explicit TLB invalidation instructions
- **Combined**: Hardware-assisted software invalidation

## Page Fault Handling

### What is a Page Fault?

**Page Fault**: Access to page not in physical memory

**Causes**:
- **Not present**: Page never loaded
- **Protection violation**: Insufficient permissions
- **Invalid address**: Address out of range

### Page Fault Types

**1. Minor Page Fault**:
- Page in memory but not mapped
- Map page to process
- Fast recovery

**2. Major Page Fault**:
- Page not in memory
- Must load from disk
- Slow recovery (milliseconds)

**3. Protection Fault**:
- Page in memory but wrong permissions
- Usually fatal (segmentation fault)

### Page Fault Handling Process

**Steps**:
```
1. CPU generates page fault
2. Save process state
3. Enter kernel mode
4. Check fault type:
   a. Invalid address → Kill process
   b. Protection violation → Kill process
   c. Not present → Continue
5. Find free frame (or evict page)
6. Load page from disk (if needed)
7. Update page table
8. Invalidate TLB entry
9. Resume process
```

**Performance**:
- **Minor fault**: ~1-10 microseconds
- **Major fault**: ~1-10 milliseconds (disk I/O)

### Demand Paging

**Concept**: Load pages on demand

**Benefits**:
- **Faster startup**: Don't load all pages
- **Memory efficient**: Only load what's used
- **Better utilization**: More processes fit in memory

**Process**:
```
1. Process starts
2. Page table entries marked "not present"
3. Process accesses page
4. Page fault occurs
5. Load page from disk
6. Update page table
7. Resume process
```

## Memory Protection

### Protection Mechanisms

**1. Read/Write Protection**:
```
Page table entry: R/W flag
- R/W = 0: Read-only
- R/W = 1: Read/write

Write to read-only page → Protection fault
```

**2. User/Supervisor Protection**:
```
Page table entry: U/S flag
- U/S = 0: Supervisor (kernel) only
- U/S = 1: User accessible

User access to supervisor page → Protection fault
```

**3. Execute Protection**:
```
Page table entry: NX (No Execute) flag
- NX = 0: Executable
- NX = 1: Not executable

Execute non-executable page → Protection fault
```

### Memory Layout Protection

**Typical Layout**:
```
High Address:
  ┌─────────────┐
  │   Stack     │ ← Grows down, Read/Write, No Execute
  ├─────────────┤
  │   (unused)  │
  ├─────────────┤
  │    Heap     │ ← Grows up, Read/Write, No Execute
  ├─────────────┤
  │    Data     │ ← Read/Write, No Execute
  ├─────────────┤
  │    Code     │ ← Read-only, Execute
Low Address:
```

**Protection**:
- **Code**: Read-only, Executable
- **Data**: Read/Write, No Execute
- **Stack**: Read/Write, No Execute, Grows down
- **Heap**: Read/Write, No Execute, Grows up

## Performance Considerations

### TLB Performance

**TLB Miss Rate**:
- **Small working set**: Low miss rate
- **Large working set**: High miss rate
- **Random access**: High miss rate

**Optimization Strategies**:
- **Larger pages**: Fewer TLB entries needed
- **Better locality**: Access nearby pages
- **TLB-aware algorithms**: Minimize TLB misses

### Large Pages

**Standard Pages**: 4KB

**Large Pages**: 2MB or 1GB (x86-64)

**Benefits**:
- **Fewer TLB entries**: Cover more memory
- **Lower TLB miss rate**: Better performance
- **Less page table overhead**: Fewer entries

**Use Cases**:
- **Databases**: Large working sets
- **Scientific computing**: Large arrays
- **Virtualization**: Guest memory

**Trade-offs**:
- **Internal fragmentation**: Wasted space
- **Less flexible**: Coarser granularity

### Page Table Walking Optimization

**Hardware Support**:
- **Page walk caches**: Cache intermediate levels
- **Speculative walks**: Prefetch page tables
- **Parallel walks**: Multiple levels in parallel

**Software Optimization**:
- **Huge pages**: Fewer levels to walk
- **Page table caching**: Keep in cache
- **Efficient data structures**: Fast lookup

## Real-World Considerations

### Address Space Layout Randomization (ASLR)

**Purpose**: Security (prevent exploits)

**How It Works**:
- Randomize virtual address space layout
- Stack, heap, libraries at random addresses
- Makes exploits harder

**TLB Impact**:
- **TLB flush**: On each process start
- **Performance**: Slight overhead
- **Security**: Worth the cost

### NUMA (Non-Uniform Memory Access)

**Problem**: Multiple memory nodes, different access times

**Solution**: NUMA-aware allocation
- Allocate pages from local node
- Faster access to local memory
- Slower access to remote memory

**TLB Consideration**:
- TLB doesn't know NUMA topology
- OS must allocate appropriately
- Performance critical

## Common Pitfalls

### Problem: TLB Thrashing

**Scenario**:
```
Large working set
Small TLB
Many TLB misses
Poor performance
```

**Solution**:
- Use larger pages
- Improve locality
- Increase TLB size (hardware)
- Reduce working set

### Problem: Page Table Bloat

**Scenario**:
```
Many processes
Large address spaces
Huge page tables
Memory overhead
```

**Solution**:
- Multi-level page tables
- Sparse allocation
- Shared page tables (for shared memory)
- Larger pages

## Quiz

1. What is the main purpose of the TLB?
   - **A)** Store page tables
   - **B)** Cache page table entries for fast translation
   - **C)** Manage virtual memory
   - **D)** Handle page faults

2. Why are multi-level page tables used?
   - **A)** Faster translation
   - **B)** Reduce memory overhead for sparse address spaces
   - **C)** Simpler implementation
   - **D)** Better security

3. What happens on a TLB miss?
   - **A)** Page fault
   - **B)** Page table walk
   - **C)** Process killed
   - **D)** Memory allocation

**Answers:**
1. **B** - TLB caches page table entries to speed up virtual-to-physical address translation
2. **B** - Multi-level page tables reduce memory overhead by only allocating page tables for used pages in sparse address spaces
3. **B** - On TLB miss, the CPU performs a page table walk to find the frame number, then updates the TLB

## Next Steps

- [Process vs Threads Internals](./04.%20Process%20vs%20Threads%20Internals.md) - Process and thread management
- [Kernel Architecture](./05.%20Kernel%20Architecture.md) - Monolithic vs microkernel

