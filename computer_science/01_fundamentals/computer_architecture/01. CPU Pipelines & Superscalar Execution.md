---
number: 1
title: "CPU Pipelines & Superscalar Execution"
slug: "cpu-pipelines-superscalar-execution"
level: "fundamentals"
tags: ["computer-architecture", "cpu", "pipeline", "superscalar", "performance"]
prerequisites: []
estimated_minutes: 100
contributors: []
diagrams: []
examples: []
canonical_id: "cs-arch-01"
---

# CPU Pipelines & Superscalar Execution

## Overview

Understanding CPU pipelines and superscalar execution is fundamental to understanding modern processor performance. This comprehensive guide covers instruction pipelining, pipeline hazards, superscalar architectures, out-of-order execution, and how these techniques enable high-performance computing.

## Table of Contents

1. [Instruction Execution Basics](#basics)
2. [Instruction Pipelining](#pipelining)
3. [Pipeline Hazards](#hazards)
4. [Superscalar Execution](#superscalar)
5. [Out-of-Order Execution](#ooo)
6. [Branch Prediction](#branch-prediction)
7. [Performance Optimization](#performance)

## Instruction Execution Basics

### Traditional Execution

**Sequential Execution**:
```
Instruction 1: Fetch → Decode → Execute → Write
Instruction 2: Fetch → Decode → Execute → Write
Instruction 3: Fetch → Decode → Execute → Write
```

**Problem**: CPU idle most of the time

**Example**:
- Fetch: 1 cycle
- Decode: 1 cycle
- Execute: 1 cycle
- Write: 1 cycle
- **Total**: 4 cycles per instruction
- **Utilization**: 25% (only Execute uses ALU)

### Stages of Execution

**1. Fetch (IF)**:
- Get instruction from memory
- Update program counter

**2. Decode (ID)**:
- Decode instruction
- Read registers
- Determine operation

**3. Execute (EX)**:
- Perform operation (ALU, etc.)
- Calculate address (for loads/stores)

**4. Memory (MEM)**:
- Access memory (loads/stores)
- Bypass for other instructions

**5. Write Back (WB)**:
- Write result to register

## Instruction Pipelining

### Basic Pipeline Concept

**Idea**: Overlap execution of multiple instructions

**Pipeline**:
```
Cycle 1: IF1
Cycle 2: ID1 | IF2
Cycle 3: EX1 | ID2 | IF3
Cycle 4: MEM1 | EX2 | ID3 | IF4
Cycle 5: WB1 | MEM2 | EX3 | ID4 | IF5
```

**Result**: One instruction completes per cycle (after pipeline fill)

### 5-Stage Pipeline

**Stages**:
```
IF: Instruction Fetch
ID: Instruction Decode & Register Read
EX: Execute & Address Calculation
MEM: Memory Access
WB: Write Back to Register
```

**Timeline**:
```
      Cycle 1  Cycle 2  Cycle 3  Cycle 4  Cycle 5  Cycle 6  Cycle 7
Inst1   IF      ID       EX       MEM      WB
Inst2          IF       ID       EX       MEM      WB
Inst3                   IF       ID       EX       MEM      WB
Inst4                            IF       ID       EX       MEM      WB
```

**Throughput**: 1 instruction per cycle (after startup)

**Latency**: Still 5 cycles per instruction

### Pipeline Benefits

**Performance Improvement**:
- **Without pipeline**: 4 cycles per instruction
- **With pipeline**: 1 cycle per instruction (after fill)
- **Speedup**: ~4x (ideal case)

**Resource Utilization**:
- **Before**: Each stage used 25% of time
- **After**: Each stage used 100% of time
- **Efficiency**: Much better

## Pipeline Hazards

### What are Hazards?

**Hazard**: Situation preventing next instruction from executing

**Types**:
1. **Structural**: Resource conflict
2. **Data**: Data dependency
3. **Control**: Branch instruction

### Structural Hazards

**Problem**: Resource needed by multiple instructions

**Example**: Single memory port
```
Cycle 4: Inst1 MEM (load) | Inst4 IF (fetch)
         ↑                ↑
         Both need memory → Conflict!
```

**Solution**:
- **Separate caches**: Instruction cache + data cache
- **Multiple ports**: Multiple memory ports
- **Stall**: Wait for resource

### Data Hazards

**Problem**: Instruction depends on result of previous instruction

**Types**:
1. **RAW (Read After Write)**: True dependency
2. **WAR (Write After Read)**: Anti-dependency
3. **WAW (Write After Write)**: Output dependency

**RAW Example**:
```asm
ADD R1, R2, R3    ; R1 = R2 + R3
SUB R4, R1, R5    ; R4 = R1 - R5 (needs R1 from ADD)
```

**Timeline**:
```
      Cycle 1  Cycle 2  Cycle 3  Cycle 4  Cycle 5
ADD    IF      ID       EX       MEM      WB
SUB           IF       ID       EX?      MEM      WB
                              ↑
                         R1 not ready!
```

**Solutions**:
- **Stall**: Insert bubbles (NOPs)
- **Forwarding**: Bypass result directly
- **Register renaming**: Eliminate false dependencies

### Control Hazards

**Problem**: Branch changes instruction flow

**Example**:
```asm
BEQ R1, R2, label  ; Branch if R1 == R2
ADD R3, R4, R5     ; Next instruction (may not execute)
```

**Timeline**:
```
      Cycle 1  Cycle 2  Cycle 3  Cycle 4
BEQ    IF      ID       EX       MEM
ADD           IF       ID       EX
                              ↑
                    Branch decision made
                    ADD may be wrong instruction!
```

**Solutions**:
- **Stall**: Wait for branch decision
- **Branch prediction**: Guess branch outcome
- **Delayed branch**: Execute instruction after branch

## Superscalar Execution

### What is Superscalar?

**Superscalar**: Execute multiple instructions per cycle

**Requirements**:
- Multiple execution units
- Instruction-level parallelism (ILP)
- Dependency checking

### Superscalar Pipeline

**2-Way Superscalar**:
```
      Cycle 1  Cycle 2  Cycle 3  Cycle 4  Cycle 5
Inst1   IF      ID       EX       MEM      WB
Inst2   IF      ID       EX       MEM      WB
Inst3          IF       ID       EX       MEM      WB
Inst4          IF       ID       EX       MEM      WB
```

**Throughput**: 2 instructions per cycle (ideal)

**Requirements**:
- **No dependencies**: Instructions independent
- **Resources**: Enough execution units
- **Bandwidth**: Fetch 2 instructions per cycle

### Instruction Issue

**In-Order Issue**:
- Issue instructions in program order
- Check dependencies
- Issue if no dependencies

**Out-of-Order Issue**:
- Issue instructions out of order
- More complex
- Better performance

### Execution Units

**Types**:
- **Integer ALU**: Arithmetic operations
- **Floating Point Unit**: FP operations
- **Load/Store Unit**: Memory operations
- **Branch Unit**: Branch instructions

**Example**: 4-way superscalar
- 2 Integer ALUs
- 1 FPU
- 1 Load/Store Unit

## Out-of-Order Execution

### What is OoO?

**Out-of-Order**: Execute instructions when operands ready

**Benefits**:
- **Hide latency**: Execute independent instructions
- **Better utilization**: Keep execution units busy
- **Higher performance**: More instructions per cycle

### OoO Pipeline

**Stages**:
```
1. Fetch: Get instructions
2. Decode: Decode instructions
3. Rename: Rename registers (eliminate WAR/WAW)
4. Issue: Check dependencies, issue when ready
5. Execute: Execute out of order
6. Write-back: Write results
7. Commit: Commit in order
```

### Register Renaming

**Problem**: False dependencies (WAR, WAW)

**Example**:
```asm
ADD R1, R2, R3    ; R1 = R2 + R3
SUB R1, R4, R5    ; R1 = R4 - R5 (WAW on R1)
MUL R6, R1, R7    ; R6 = R1 * R7 (needs first R1)
```

**Renaming**:
```asm
ADD R1a, R2, R3   ; Rename R1 → R1a
SUB R1b, R4, R5   ; Rename R1 → R1b
MUL R6, R1a, R7   ; Use R1a (no dependency on SUB)
```

**Result**: SUB can execute in parallel with MUL

### Reorder Buffer (ROB)

**Purpose**: Ensure in-order commit

**Structure**:
```
Entry: [Instruction, Result, Status, Program Order]
```

**Process**:
1. Instructions execute out of order
2. Results stored in ROB
3. Commit in program order
4. Maintains sequential semantics

## Branch Prediction

### The Problem

**Branches**: 15-20% of instructions

**Cost**: 3-5 cycle penalty if mispredicted

**Impact**: Significant performance loss

### Branch Prediction Strategies

**1. Static Prediction**:
- **Always taken**: Predict branch always taken
- **Always not taken**: Predict branch never taken
- **Backward taken**: Loops usually taken
- **Simple**: No hardware needed

**2. Dynamic Prediction**:
- **1-bit predictor**: Last outcome
- **2-bit predictor**: History with hysteresis
- **Branch Target Buffer (BTB)**: Cache target addresses
- **Better**: Adapts to branch behavior

### 2-Bit Predictor

**States**:
```
Strongly Not Taken (00) → Not Taken → Weakly Not Taken (01)
Weakly Not Taken (01)   → Not Taken → Strongly Not Taken (00)
Weakly Taken (10)       → Taken     → Strongly Taken (11)
Strongly Taken (11)     → Taken     → Strongly Taken (11)
```

**Hysteresis**: Requires 2 mispredictions to change prediction

**Accuracy**: ~90-95% for typical code

### Branch Target Buffer (BTB)

**Purpose**: Cache branch targets

**Structure**:
```
Entry: [PC, Target Address, Prediction]
```

**Process**:
1. Check BTB on fetch
2. If hit: Use predicted target
3. If miss: Predict not taken
4. Update BTB on branch resolution

## Performance Optimization

### Pipeline Optimization

**1. Reduce Hazards**:
- **Code scheduling**: Reorder instructions
- **Register renaming**: Eliminate false dependencies
- **Forwarding**: Bypass pipeline stages

**2. Increase ILP**:
- **Loop unrolling**: More independent instructions
- **Software pipelining**: Overlap loop iterations
- **SIMD**: Process multiple data elements

**3. Improve Branch Prediction**:
- **Profile-guided**: Use execution profiles
- **Hint instructions**: Provide branch hints
- **Predicated execution**: Eliminate branches

### Code Example

**Before Optimization**:
```c
for (int i = 0; i < n; i++) {
    a[i] = b[i] + c[i];
}
```

**After Loop Unrolling**:
```c
for (int i = 0; i < n; i += 4) {
    a[i]   = b[i]   + c[i];
    a[i+1] = b[i+1] + c[i+1];
    a[i+2] = b[i+2] + c[i+2];
    a[i+3] = b[i+3] + c[i+3];
}
```

**Benefits**:
- **More ILP**: 4 independent operations
- **Fewer branches**: 1/4 the branches
- **Better pipeline utilization**: Less stall time

## Real-World Considerations

### Modern Processors

**Intel Core i7**:
- **Pipeline depth**: ~14-20 stages
- **Superscalar**: 4-6 instructions per cycle
- **Out-of-order**: 100+ instructions in flight
- **Branch prediction**: Very sophisticated

**ARM Cortex-A78**:
- **Pipeline depth**: ~13 stages
- **Superscalar**: 3-4 instructions per cycle
- **Out-of-order**: 80+ instructions in flight
- **Power efficient**: Good performance/power

### Performance Limits

**1. Instruction-Level Parallelism**:
- **Limited**: Dependencies reduce ILP
- **Typical**: 2-4 instructions per cycle
- **Theoretical**: Higher, but dependencies limit

**2. Memory Latency**:
- **Cache miss**: 100-300 cycles
- **Impact**: Significant performance loss
- **Solution**: Prefetching, better caches

**3. Branch Mispredictions**:
- **Cost**: 10-20 cycles
- **Impact**: Can dominate performance
- **Solution**: Better predictors, fewer branches

## Common Pitfalls

### Problem: Assuming Perfect Pipeline

```c
// BAD: Assume 1 cycle per instruction
for (int i = 0; i < n; i++) {
    sum += array[i]; // May have dependencies
}

// GOOD: Consider dependencies and optimize
int sum1 = 0, sum2 = 0;
for (int i = 0; i < n; i += 2) {
    sum1 += array[i];
    sum2 += array[i+1]; // Independent operations
}
sum = sum1 + sum2;
```

### Problem: Ignoring Branch Prediction

```c
// BAD: Unpredictable branches
if (random() > 0.5) {
    // Unpredictable
}

// GOOD: Predictable patterns
if (likely_condition) {
    // Usually taken
}
```

## Quiz

1. What is the main benefit of pipelining?
   - **A)** Reduces instruction latency
   - **B)** Increases instruction throughput
   - **C)** Simplifies CPU design
   - **D)** Reduces power consumption

2. What is a data hazard?
   - **A)** Resource conflict
   - **B)** Instruction depends on result of previous instruction
   - **C)** Branch instruction
   - **D)** Cache miss

3. What does superscalar execution enable?
   - **A)** Faster clock speed
   - **B)** Multiple instructions per cycle
   - **C)** Lower power
   - **D)** Simpler design

**Answers:**
1. **B** - Pipelining increases instruction throughput by allowing multiple instructions to be in different stages simultaneously
2. **B** - A data hazard occurs when an instruction depends on the result of a previous instruction that hasn't completed yet
3. **B** - Superscalar execution allows multiple instructions to be executed per cycle by using multiple execution units

## Next Steps

- [Branch Prediction & Speculation](../computer_architecture/02.%20Branch%20Prediction%20%26%20Speculation.md) - Advanced branch prediction
- [Caches & Cache Coherence](../computer_architecture/03.%20Caches%20%26%20Cache%20Coherence.md) - Memory hierarchy

