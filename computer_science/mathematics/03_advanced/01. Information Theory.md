---
number: 1
title: "Information Theory"
slug: "information-theory"
level: "advanced"
tags: ["mathematics", "information-theory", "entropy", "mutual-information", "coding"]
prerequisites: ["optimization-theory-convex-optimization"]
estimated_minutes: 150
contributors: []
diagrams: []
examples: []
canonical_id: "cs-math-adv-01"
---

# Information Theory

## Overview

Information theory quantifies information, entropy, and communication limits. Understanding entropy, mutual information, channel capacity, and coding theory is essential for data compression, cryptography, machine learning, and communication systems.

## Table of Contents

1. [What is Information Theory?](#what-is-information-theory)
2. [Entropy](#entropy)
3. [Mutual Information](#mutual-information)
4. [Channel Capacity](#channel-capacity)
5. [Source Coding](#source-coding)
6. [Channel Coding](#channel-coding)
7. [Shannon's Theorems](#shannon-theorems)
8. [Applications](#applications)

## What is Information Theory?

### Definition

**Information Theory**: Study of information

**Founder**: Claude Shannon

**Concepts**: 
- **Information**: Quantify information
- **Entropy**: Measure uncertainty
- **Capacity**: Communication limits
- **Coding**: Efficient encoding

**Use**: Compression, cryptography, ML

### Information Theory Applications

**1. Data Compression**:
```
Compress data efficiently
```

**2. Error Correction**:
```
Correct transmission errors
```

**3. Cryptography**:
```
Secure communication
```

**4. Machine Learning**:
```
Feature selection, information gain
```

## Entropy

### What is Entropy?

**Entropy**: Measure of uncertainty

**Definition**: 
```
H(X) = -Σ p(x) log₂ p(x)
```

**Properties**: 
- **Maximum**: Uniform distribution
- **Minimum**: Deterministic (0)
- **Units**: Bits

**Use**: Measure information content

### Entropy Example

**Example**: 
```
Fair coin: H = 1 bit
Biased coin (p=0.9): H ≈ 0.47 bits
Deterministic: H = 0 bits
```

**Meaning**: More uncertainty = more entropy

## Mutual Information

### What is Mutual Information?

**Mutual Information**: Information shared

**Definition**: 
```
I(X;Y) = H(X) - H(X|Y)
```

**Properties**: 
- **Symmetric**: I(X;Y) = I(Y;X)
- **Non-negative**: I(X;Y) ≥ 0
- **Zero**: If X, Y independent

**Use**: Feature selection, dependencies

### Mutual Information Example

**Example**: 
```
X: Weather
Y: Temperature
I(X;Y): Information shared
```

**Use**: Measure dependence

## Channel Capacity

### What is Channel Capacity?

**Channel Capacity**: Maximum information rate

**Shannon Capacity**: 
```
C = max I(X;Y)
```

**Units**: Bits per channel use

**Use**: Communication limits

### Channel Capacity Example

**Example**: 
```
Noisy channel: C = 1 - H(error)
Perfect channel: C = 1
```

**Meaning**: Maximum reliable rate

## Source Coding

### What is Source Coding?

**Source Coding**: Compress source

**Goal**: 
```
Minimize expected length
```

**Shannon's Source Coding Theorem**: 
```
Average length ≥ H(X)
```

**Optimal**: Achieve H(X)

**Use**: Data compression

### Huffman Coding

**Huffman Coding**: Optimal prefix code

**Method**: 
```
1. Build frequency tree
2. Assign codes
3. Encode symbols
```

**Optimal**: For given frequencies

**Use**: Compression

## Channel Coding

### What is Channel Coding?

**Channel Coding**: Add redundancy

**Goal**: 
```
Correct errors
```

**Shannon's Channel Coding Theorem**: 
```
Reliable communication if rate < C
```

**Codes**: 
- **Error Detection**: Detect errors
- **Error Correction**: Correct errors

**Use**: Reliable communication

### Error Correction Codes

**Types**: 
- **Hamming Codes**: Simple codes
- **Reed-Solomon**: Block codes
- **LDPC**: Low-density parity-check
- **Turbo Codes**: Concatenated codes

**Use**: Correct transmission errors

## Shannon's Theorems

### Source Coding Theorem

**Source Coding Theorem**: 
```
Average code length ≥ H(X)
Can achieve H(X) asymptotically
```

**Implication**: Entropy is compression limit

### Channel Coding Theorem

**Channel Coding Theorem**: 
```
Reliable communication if R < C
Impossible if R > C
```

**Implication**: Capacity is communication limit

## Applications

### Application 1: Data Compression

**Use**: Compress files

**Method**: 
- **Entropy**: Measure information
- **Coding**: Efficient encoding
- **Huffman**: Optimal codes

**Result**: Compressed data

### Application 2: Machine Learning

**Use**: Feature selection

**Method**: 
- **Mutual Information**: Measure relevance
- **Information Gain**: Select features
- **Entropy**: Measure uncertainty

**Result**: Selected features

## Real-World Examples

### Example 1: ZIP Compression

**Use**: File compression

**Method**: 
- **Entropy**: Measure information
- **Coding**: Efficient encoding
- **LZ77/LZ78**: Dictionary methods

**Result**: Compressed files

### Example 2: Error Correction

**Use**: Reliable communication

**Method**: 
- **Channel Coding**: Add redundancy
- **Reed-Solomon**: Error correction
- **Decoding**: Correct errors

**Result**: Reliable transmission

## Common Pitfalls

### Problem: Confusing Entropy

```c
// BAD: Think entropy = randomness
// Incorrect understanding

// GOOD: Entropy = uncertainty/information
// Correct interpretation
```

## Quiz

1. What is entropy?
   - **A)** Energy
   - **B)** Measure of uncertainty/information content
   - **C)** Temperature
   - **D)** Pressure

2. What is mutual information?
   - **A)** Independent information
   - **B)** Information shared between variables
   - **C)** Total information
   - **D)** No information

3. What is channel capacity?
   - **A)** Channel size
   - **B)** Maximum reliable information rate through channel
   - **C)** Channel width
   - **D)** Channel length

**Answers:**
1. **B** - Entropy H(X) measures uncertainty/information content, with maximum for uniform distribution
2. **B** - Mutual information I(X;Y) measures information shared between variables, zero if independent
3. **B** - Channel capacity C is the maximum information rate (bits per use) that can be reliably transmitted

## Next Steps

- [Game Theory](./02.%20Game%20Theory.md) - Game theory
- [Topology for CS](./03.%20Topology%20for%20CS.md) - Topology

