---
number: 3
title: "Linear Algebra Fundamentals"
slug: "linear-algebra-fundamentals"
level: "fundamentals"
tags: ["mathematics", "linear-algebra", "vectors", "matrices", "eigenvalues"]
prerequisites: ["discrete-mathematics-fundamentals"]
estimated_minutes: 120
contributors: []
diagrams: []
examples: []
canonical_id: "cs-math-03"
---

# Linear Algebra Fundamentals

## Overview

Linear algebra is fundamental to computer science, especially for machine learning, computer graphics, data analysis, and scientific computing. Understanding vectors, matrices, operations, and key concepts like eigenvalues and eigenvectors is essential for many advanced topics.

## Table of Contents

1. [Vectors](#vectors)
2. [Vector Operations](#vector-operations)
3. [Matrices](#matrices)
4. [Matrix Operations](#matrix-operations)
5. [Matrix Multiplication](#matrix-multiplication)
6. [Linear Transformations](#linear-transformations)
7. [Eigenvalues & Eigenvectors](#eigenvalues)
8. [Applications](#applications)

## Vectors

### What is a Vector?

**Vector**: Ordered list of numbers

**Notation**: v = [v₁, v₂, ..., vₙ]

**Dimensions**: n-dimensional vector

**Example**: v = [3, 4, 5] (3D vector)

### Vector Representation

**Column Vector**:
```
v = [v₁]
    [v₂]
    [v₃]
```

**Row Vector**:
```
v = [v₁, v₂, v₃]
```

**Geometric**: Vector as arrow in space

## Vector Operations

### Vector Addition

**Operation**: Add component-wise

**Formula**: u + v = [u₁ + v₁, u₂ + v₂, ..., uₙ + vₙ]

**Example**:
```
u = [1, 2, 3]
v = [4, 5, 6]
u + v = [5, 7, 9]
```

### Scalar Multiplication

**Operation**: Multiply each component

**Formula**: c × v = [c×v₁, c×v₂, ..., c×vₙ]

**Example**:
```
v = [1, 2, 3]
2 × v = [2, 4, 6]
```

### Dot Product

**Operation**: Sum of products

**Formula**: u · v = u₁v₁ + u₂v₂ + ... + uₙvₙ

**Example**:
```
u = [1, 2, 3]
v = [4, 5, 6]
u · v = 1×4 + 2×5 + 3×6 = 4 + 10 + 18 = 32
```

**Geometric**: u · v = |u| × |v| × cos(θ)

### Cross Product (3D)

**Operation**: Vector perpendicular to both

**Formula**:
```
u × v = [u₂v₃ - u₃v₂,
         u₃v₁ - u₁v₃,
         u₁v₂ - u₂v₁]
```

**Example**:
```
u = [1, 0, 0]
v = [0, 1, 0]
u × v = [0, 0, 1]
```

## Matrices

### What is a Matrix?

**Matrix**: Rectangular array of numbers

**Notation**: A = [aᵢⱼ]

**Dimensions**: m × n (m rows, n columns)

**Example**:
```
A = [1  2  3]
    [4  5  6]
    (2×3 matrix)
```

### Matrix Types

**1. Square Matrix**: m = n

**2. Identity Matrix**: I (1s on diagonal, 0s elsewhere)

**3. Diagonal Matrix**: Non-zero only on diagonal

**4. Symmetric Matrix**: A = Aᵀ

## Matrix Operations

### Matrix Addition

**Operation**: Add component-wise

**Formula**: (A + B)ᵢⱼ = aᵢⱼ + bᵢⱼ

**Requirement**: Same dimensions

**Example**:
```
A = [1  2]    B = [5  6]
    [3  4]        [7  8]
    
A + B = [6   8]
        [10 12]
```

### Scalar Multiplication

**Operation**: Multiply each element

**Formula**: (cA)ᵢⱼ = c × aᵢⱼ

**Example**:
```
A = [1  2]
    [3  4]
    
2A = [2  4]
     [6  8]
```

### Matrix Transpose

**Operation**: Swap rows and columns

**Formula**: (Aᵀ)ᵢⱼ = aⱼᵢ

**Example**:
```
A = [1  2  3]
    [4  5  6]
    
Aᵀ = [1  4]
     [2  5]
     [3  6]
```

## Matrix Multiplication

### Matrix Multiplication Rules

**Dimensions**: A (m×n) × B (n×p) = C (m×p)

**Formula**: cᵢⱼ = Σₖ aᵢₖ × bₖⱼ

**Example**:
```
A = [1  2]    B = [5  6]
    [3  4]        [7  8]
    
C = A × B:
  c₁₁ = 1×5 + 2×7 = 19
  c₁₂ = 1×6 + 2×8 = 22
  c₂₁ = 3×5 + 4×7 = 43
  c₂₂ = 3×6 + 4×8 = 50
  
C = [19  22]
    [43  50]
```

### Matrix Multiplication Properties

**Not Commutative**: AB ≠ BA (in general)

**Associative**: (AB)C = A(BC)

**Distributive**: A(B + C) = AB + AC

**Identity**: AI = IA = A

## Linear Transformations

### What are Linear Transformations?

**Transformation**: Function mapping vectors to vectors

**Linear**: Preserves addition and scalar multiplication

**Matrix Form**: T(v) = Av

**Example**: Rotation, scaling, reflection

### Common Transformations

**1. Rotation** (2D):
```
R = [cos(θ)  -sin(θ)]
    [sin(θ)   cos(θ)]
```

**2. Scaling**:
```
S = [sₓ  0 ]
    [0   sᵧ]
```

**3. Reflection**:
```
Reflect over x-axis:
  [1   0]
  [0  -1]
```

## Eigenvalues & Eigenvectors

### Definition

**Eigenvector**: Non-zero vector v such that Av = λv

**Eigenvalue**: Scalar λ

**Meaning**: Transformation only scales vector, doesn't change direction

### Finding Eigenvalues

**Characteristic Equation**: det(A - λI) = 0

**Example**:
```
A = [3  1]
    [0  2]
    
A - λI = [3-λ  1  ]
         [0    2-λ]
         
det = (3-λ)(2-λ) = 0
λ = 3 or λ = 2
```

### Finding Eigenvectors

**For each eigenvalue**: Solve (A - λI)v = 0

**Example** (λ = 3):
```
[0  1][v₁]   [0]
[0 -1][v₂] = [0]

v₂ = 0, v₁ free
Eigenvector: [1, 0]
```

## Applications

### Machine Learning

**Neural Networks**: Matrix multiplications

**Linear Regression**: y = Xw + b

**Principal Component Analysis**: Eigenvalue decomposition

### Computer Graphics

**Transformations**: Rotation, scaling, translation

**3D Rendering**: Matrix operations

**Projection**: Perspective projection matrices

### Data Analysis

**Principal Component Analysis**: Reduce dimensions

**Singular Value Decomposition**: Matrix factorization

**Linear Systems**: Solve Ax = b

## Real-World Examples

### Example 1: Image Processing

**Transformation**: Rotate image

**Matrix**: Rotation matrix

**Operation**: Multiply pixel coordinates

### Example 2: Machine Learning

**Neural Network Layer**:
```
y = ReLU(Wx + b)
Where:
  W: Weight matrix
  x: Input vector
  b: Bias vector
```

### Example 3: 3D Graphics

**Model Transformation**:
```
World coordinates → View coordinates → Screen coordinates
Each step: Matrix multiplication
```

## Common Pitfalls

### Problem: Matrix Multiplication Order

```python
# BAD: Wrong order
result = B @ A  # May not be what you want

# GOOD: Correct order
result = A @ B  # Intended operation
```

### Problem: Dimension Mismatch

```python
# BAD: Incompatible dimensions
A = np.array([[1, 2], [3, 4]])  # 2×2
B = np.array([[1, 2, 3]])        # 1×3
C = A @ B  # Error!

# GOOD: Compatible dimensions
A = np.array([[1, 2], [3, 4]])  # 2×2
B = np.array([[1, 2], [3, 4]])  # 2×2
C = A @ B  # Works: 2×2
```

## Quiz

1. What is the dot product of two vectors?
   - **A)** A vector
   - **B)** Sum of products of corresponding components (scalar)
   - **C)** A matrix
   - **D)** Cross product

2. What are eigenvalues and eigenvectors?
   - **A)** Matrix dimensions
   - **B)** Scalar and vector where Av = λv (transformation scales vector)
   - **C)** Matrix operations
   - **D)** Vector components

3. What is matrix multiplication?
   - **A)** Element-wise multiplication
   - **B)** Dot product of rows and columns
   - **C)** Addition
   - **D)** Transpose

**Answers:**
1. **B** - The dot product of two vectors is the sum of products of corresponding components, resulting in a scalar value
2. **B** - An eigenvector is a non-zero vector v and eigenvalue is a scalar λ such that Av = λv, meaning the transformation only scales the vector without changing its direction
3. **B** - Matrix multiplication computes each element as the dot product of the corresponding row from the first matrix and column from the second matrix

## Next Steps

- [Graph Theory Advanced](./04.%20Graph%20Theory%20Advanced.md) - Advanced graph concepts
- [Number Theory Fundamentals](./05.%20Number%20Theory%20Fundamentals.md) - Number theory basics

