---
number: 8
title: "Service Discovery - Consul, etcd, ZooKeeper"
slug: "service-discovery-consul-etcd-zookeeper"
level: "intermediate"
tags: ["distributed-systems", "service-discovery", "consul", "etcd", "zookeeper"]
prerequisites: ["distributed-tracing"]
estimated_minutes: 135
contributors: []
diagrams: []
examples: []
canonical_id: "cs-dist-08"
---

# Service Discovery - Consul, etcd, ZooKeeper

## Overview

Service discovery enables services to find and communicate with each other in distributed systems. Understanding service discovery patterns, tools like Consul, etcd, and ZooKeeper, and their architectures is essential for building microservices and distributed applications.

## Table of Contents

1. [What is Service Discovery?](#what-is-service-discovery)
2. [Service Discovery Patterns](#patterns)
3. [Consul](#consul)
4. [etcd](#etcd)
5. [ZooKeeper](#zookeeper)
6. [Comparison](#comparison)
7. [Service Mesh Integration](#service-mesh)
8. [Best Practices](#best-practices)

## What is Service Discovery?

### Definition

**Service Discovery**: Mechanism to find services

**Purpose**: 
- **Location**: Find service locations
- **Health**: Check service health
- **Load Balancing**: Load balancing
- **Configuration**: Service configuration

**Benefits**: 
- **Dynamic**: Handle dynamic services
- **Resilience**: Resilience to failures
- **Scalability**: Scale services

### Service Discovery Types

**1. Client-Side Discovery**:
```
Client queries service registry
```

**2. Server-Side Discovery**:
```
Load balancer queries registry
```

**3. Service Registry**:
```
Central registry
```

**4. Service Mesh**:
```
Service mesh handles discovery
```

## Service Discovery Patterns

### Pattern 1: Service Registry

**Service Registry**: Central registry

**Components**:
- **Registry**: Service registry
- **Registration**: Service registration
- **Discovery**: Service discovery

**Flow**:
```
1. Service registers with registry
2. Client queries registry
3. Registry returns service location
4. Client connects to service
```

### Pattern 2: Service Mesh

**Service Mesh**: Infrastructure layer

**Features**: 
- **Discovery**: Automatic discovery
- **Load Balancing**: Load balancing
- **Security**: Security policies

**Use**: Microservices

## Consul

### What is Consul?

**Consul**: Service discovery and configuration

**Features**: 
- **Service Discovery**: Service discovery
- **Health Checking**: Health checking
- **Key-Value Store**: Key-value store
- **Multi-Datacenter**: Multi-datacenter support

**Use**: Microservices, distributed systems

### Consul Architecture

**Components**:
- **Agents**: Consul agents
- **Servers**: Consul servers
- **Clients**: Consul clients

**Consensus**: Raft consensus

**Service Registration**:
```json
{
  "ID": "web1",
  "Name": "web",
  "Tags": ["production"],
  "Address": "10.0.0.1",
  "Port": 8080,
  "Check": {
    "HTTP": "http://10.0.0.1:8080/health",
    "Interval": "10s"
  }
}
```

### Consul Features

**1. Service Discovery**:
```
DNS or HTTP API
```

**2. Health Checking**:
```
Multiple health check types
```

**3. Key-Value Store**:
```
Distributed key-value store
```

**4. Multi-Datacenter**:
```
Multi-datacenter support
```

## etcd

### What is etcd?

**etcd**: Distributed key-value store

**Features**: 
- **Key-Value Store**: Key-value store
- **Watch**: Watch for changes
- **Consensus**: Raft consensus
- **TTL**: Time-to-live keys

**Use**: Kubernetes, service discovery

### etcd Architecture

**Components**:
- **etcd Cluster**: etcd cluster
- **Raft**: Raft consensus
- **API**: REST API

**Service Registration**:
```bash
# Register service
etcdctl put /services/web/instance1 '{"host":"10.0.0.1","port":8080}'

# Discover service
etcdctl get /services/web/instance1

# Watch for changes
etcdctl watch /services/web --prefix
```

### etcd Features

**1. Key-Value Store**:
```
Distributed key-value store
```

**2. Watch**:
```
Watch for key changes
```

**3. TTL**:
```
Time-to-live keys
```

**4. Consistency**:
```
Strong consistency
```

## ZooKeeper

### What is ZooKeeper?

**ZooKeeper**: Distributed coordination service

**Features**: 
- **Hierarchical Namespace**: Tree structure
- **Watches**: Watch for changes
- **Consensus**: ZAB consensus
- **Coordination**: Coordination primitives

**Use**: Hadoop, Kafka, coordination

### ZooKeeper Architecture

**Components**:
- **ZooKeeper Ensemble**: ZooKeeper cluster
- **ZAB**: ZooKeeper Atomic Broadcast
- **ZNodes**: Data nodes

**Service Registration**:
```bash
# Create ephemeral node
create /services/web/instance1 "10.0.0.1:8080" ephemeral

# List services
ls /services/web

# Watch for changes
stat /services/web watch
```

### ZooKeeper Features

**1. Hierarchical Namespace**:
```
Tree structure
```

**2. Ephemeral Nodes**:
```
Ephemeral nodes (auto-delete)
```

**3. Watches**:
```
Watch for changes
```

**4. Coordination**:
```
Coordination primitives
```

## Comparison

### Comparison Table

| Feature | Consul | etcd | ZooKeeper |
|---------|--------|------|-----------|
| **Primary Use** | Service discovery | Key-value store | Coordination |
| **Consensus** | Raft | Raft | ZAB |
| **API** | HTTP, DNS | REST | Native client |
| **Health Checks** | Built-in | External | External |
| **Multi-DC** | Yes | Limited | Limited |

### When to Use Each

**Consul**: 
- **Service Discovery**: Service discovery focus
- **Health Checks**: Built-in health checks
- **Multi-DC**: Multi-datacenter

**etcd**: 
- **Kubernetes**: Kubernetes integration
- **Key-Value**: Key-value store focus
- **Watch**: Watch functionality

**ZooKeeper**: 
- **Coordination**: Coordination primitives
- **Hadoop/Kafka**: Hadoop, Kafka
- **Locks**: Distributed locks

## Service Mesh Integration

### Service Mesh

**Service Mesh**: Infrastructure layer

**Features**: 
- **Discovery**: Automatic discovery
- **Load Balancing**: Load balancing
- **Security**: mTLS
- **Observability**: Observability

**Examples**: Istio, Linkerd

### Service Mesh Discovery

**Automatic Discovery**: 
```
Service mesh handles discovery
No manual registration
```

**Benefit**: Simplified service discovery

## Best Practices

### Practice 1: Health Checks

**Health Checks**: 
```
Implement health checks
Register with discovery
```

**Benefit**: Automatic failure detection

### Practice 2: TTL/Ephemeral Nodes

**TTL/Ephemeral**: 
```
Use TTL or ephemeral nodes
Automatic cleanup
```

**Benefit**: Handle failures

### Practice 3: Watch for Changes

**Watch**: 
```
Watch for service changes
Update connections
```

**Benefit**: Dynamic updates

## Real-World Examples

### Example 1: Microservices

**Use**: Microservices architecture

**Tool**: Consul

**Features**: 
- **Discovery**: Service discovery
- **Health**: Health checking
- **Config**: Configuration

**Result**: Dynamic microservices

### Example 2: Kubernetes

**Use**: Kubernetes service discovery

**Tool**: etcd

**Features**: 
- **Storage**: Cluster state storage
- **Discovery**: Service discovery
- **Config**: Configuration

**Result**: Kubernetes coordination

## Common Pitfalls

### Problem: No Health Checks

```c
// BAD: No health checks
// Dead services not removed

// GOOD: Implement health checks
// Automatic cleanup
```

### Problem: Stale Registrations

```c
// BAD: Services not deregistered
// Stale entries

// GOOD: Use TTL/ephemeral nodes
// Automatic cleanup
```

## Quiz

1. What is service discovery?
   - **A)** Service creation
   - **B)** Mechanism to find and locate services in distributed systems
   - **C)** Service deletion
   - **D)** Service execution

2. What is Consul?
   - **A)** Database
   - **B)** Service discovery and configuration tool with health checking
   - **C)** Cache
   - **D)** Load balancer

3. What is etcd?
   - **A)** Service discovery tool
   - **B)** Distributed key-value store used by Kubernetes
   - **C)** Database
   - **D)** Cache

**Answers:**
1. **B** - Service discovery enables services to find and communicate with each other, handling dynamic service locations and health
2. **B** - Consul is a service discovery and configuration tool with built-in health checking, multi-datacenter support, and key-value storage
3. **B** - etcd is a distributed key-value store with watch capabilities, used by Kubernetes for cluster state and service discovery

## Next Steps

- [Distributed Caching](../distributed_systems/09.%20Distributed%20Caching.md) - Redis, Memcached
- [Distributed Locking](../distributed_systems/10.%20Distributed%20Locking.md) - Distributed locks

