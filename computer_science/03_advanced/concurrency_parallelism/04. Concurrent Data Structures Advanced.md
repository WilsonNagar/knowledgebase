---
number: 4
title: "Concurrent Data Structures Advanced"
slug: "concurrent-data-structures-advanced"
level: "advanced"
tags: ["concurrency", "data-structures", "concurrent", "lock-free", "wait-free"]
prerequisites: ["transactional-memory"]
estimated_minutes: 130
contributors: []
diagrams: []
examples: []
canonical_id: "cs-conc-adv-04"
---

# Concurrent Data Structures Advanced

## Overview

Advanced concurrent data structures provide thread-safe operations without traditional locks. Understanding sophisticated lock-free and wait-free implementations, their correctness proofs, and performance characteristics is essential for building high-performance concurrent systems.

## Table of Contents

1. [Concurrent Data Structure Design](#design)
2. [Lock-Free Linked List](#lock-free-list)
3. [Lock-Free Hash Table](#lock-free-hash-table)
4. [Wait-Free Structures](#wait-free)
5. [Correctness Verification](#correctness)
6. [Performance Analysis](#performance)
7. [Memory Ordering](#memory-ordering)
8. [Real-World Examples](#examples)

## Concurrent Data Structure Design

### Design Principles

**1. Linearizability**:
```
Operations appear atomic
```

**2. Progress Guarantees**:
```
Lock-free or wait-free
```

**3. Performance**:
```
Low overhead
Good scalability
```

**4. Correctness**:
```
Proven correct
```

## Lock-Free Linked List

### Challenge

**Linked List**: More complex than stack

**Operations**: Insert, Delete, Search

**Challenge**: Concurrent modifications

### Lock-Free List Implementation

**Node Structure**:
```c
typedef struct Node {
    int key;
    int value;
    struct Node* next;  // Atomic
    bool marked;  // Marked for deletion
} Node;
```

**Search**:
```c
Node* search(int key, Node** pred, Node** curr) {
    Node* prev = head;
    Node* cur = head->next;
    
    while (cur != NULL) {
        if (cur->marked) {
            // Help delete marked node
            if (atomic_compare_exchange_weak(&prev->next, &cur, cur->next)) {
                cur = cur->next;
            } else {
                // Retry from head
                return search(key, pred, curr);
            }
        } else if (cur->key >= key) {
            *pred = prev;
            *curr = cur;
            return cur;
        }
        prev = cur;
        cur = cur->next;
    }
    *pred = prev;
    *curr = NULL;
    return NULL;
}
```

**Insert**:
```c
bool insert(int key, int value) {
    Node* new_node = malloc(sizeof(Node));
    new_node->key = key;
    new_node->value = value;
    new_node->marked = false;
    
    while (true) {
        Node* pred, *curr;
        Node* found = search(key, &pred, &curr);
        
        if (found != NULL && found->key == key) {
            free(new_node);
            return false;  // Already exists
        }
        
        new_node->next = curr;
        if (atomic_compare_exchange_weak(&pred->next, &curr, new_node)) {
            return true;
        }
        // Retry
    }
}
```

## Lock-Free Hash Table

### Design

**Structure**: Array of lock-free lists

**Hash Function**: Maps key to bucket

**Operations**: Insert, Delete, Lookup

**Challenge**: Resizing

### Lock-Free Hash Table

**Buckets**: Lock-free linked lists

**Insert**:
```
1. Hash key to bucket
2. Insert into bucket's list
```

**Lookup**:
```
1. Hash key to bucket
2. Search in bucket's list
```

**Delete**:
```
1. Hash key to bucket
2. Delete from bucket's list
```

## Wait-Free Structures

### What is Wait-Free?

**Wait-Free**: All threads make progress

**Stronger**: Than lock-free

**Guarantee**: Bounded number of steps

**Use**: Real-time systems

### Wait-Free Queue

**Challenge**: Very difficult

**Method**: 
- **Help Mechanism**: Threads help each other
- **Bounded Retries**: Limit retries

**Complexity**: High

## Correctness Verification

### Linearizability

**Definition**: Operations appear atomic

**Method**: Show linearization points

**Example**: CAS operation is linearization point

### Progress Guarantees

**Lock-Free**: At least one thread progresses

**Wait-Free**: All threads progress

**Proof**: Show algorithm satisfies guarantee

## Performance Analysis

### Metrics

**1. Throughput**:
```
Operations per second
```

**2. Latency**:
```
Time per operation
```

**3. Scalability**:
```
How performance scales with threads
```

### Factors

**1. Contention**:
```
High contention → More retries
```

**2. Memory Ordering**:
```
Stronger ordering → Slower
```

**3. Cache Effects**:
```
False sharing → Poor performance
```

## Memory Ordering

### Ordering Requirements

**Acquire**: Read operations

**Release**: Write operations

**Acquire-Release**: Both

**Sequential Consistency**: Strongest

### Trade-offs

**Weaker Ordering**: Faster, but harder to reason

**Stronger Ordering**: Slower, but easier to reason

**Choice**: Balance performance and correctness

## Real-World Examples

### Example 1: Java ConcurrentHashMap

**Use**: Thread-safe hash map

**Method**: Lock striping

**Benefit**: Good performance

### Example 2: Lock-Free Queues

**Use**: High-performance message queues

**Method**: Lock-free algorithms

**Benefit**: Low latency

## Common Pitfalls

### Problem: ABA Problem

```c
// BAD: Simple CAS
// May have ABA problem

// GOOD: Use tagged pointers
// Or hazard pointers
```

### Problem: Memory Reclamation

```c
// BAD: Free immediately
free(node);  // Other threads may access!

// GOOD: Use hazard pointers
// Or epoch-based reclamation
```

## Quiz

1. What is linearizability?
   - **A)** Linear algorithm
   - **B)** Property that operations appear atomic
   - **C)** Linear time
   - **D)** Linear memory

2. What is wait-free?
   - **A)** No waiting
   - **B)** All threads guaranteed to make progress
   - **C)** Fast
   - **D)** Simple

3. What is the main challenge in lock-free data structures?
   - **A)** Speed
   - **B)** Memory reclamation and avoiding ABA problem
   - **C)** Complexity
   - **D)** Memory usage

**Answers:**
1. **B** - Linearizability means that each operation appears to execute atomically at some point between its invocation and response, making concurrent operations appear sequential
2. **B** - Wait-free guarantees that all threads make progress (complete operations) within a bounded number of steps, stronger than lock-free which only guarantees some thread progresses
3. **B** - Main challenges include safely reclaiming memory (other threads may still reference nodes) and avoiding the ABA problem where values change but appear the same

## Next Steps

- [Advanced Concurrency Patterns](../concurrency_parallelism/05.%20Advanced%20Concurrency%20Patterns.md) - Concurrency patterns
- [Performance Optimization](../concurrency_parallelism/06.%20Performance%20Optimization.md) - Optimization techniques

