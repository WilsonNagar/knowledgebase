---
number: 9
title: "LRU & LFU Cache Algorithms"
slug: "lru-lfu-cache-algorithms"
level: "intermediate"
tags: ["data-structures", "caching", "lru", "lfu", "algorithms"]
prerequisites: ["hash-tables-hashing"]
estimated_minutes: 115
contributors: []
diagrams: []
examples: []
canonical_id: "cs-dsa-09"
---

# LRU & LFU Cache Algorithms

## Overview

LRU (Least Recently Used) and LFU (Least Frequently Used) are popular cache eviction policies. Understanding these algorithms, their implementations, and trade-offs is essential for building efficient caching systems and optimizing memory usage.

## Table of Contents

1. [Cache Eviction Problem](#cache-problem)
2. [LRU Algorithm](#lru)
3. [LRU Implementation](#lru-implementation)
4. [LFU Algorithm](#lfu)
5. [LFU Implementation](#lfu-implementation)
6. [Other Cache Policies](#other-policies)
7. [Comparison](#comparison)
8. [Applications](#applications)

## Cache Eviction Problem

### The Problem

**Cache**: Limited size storage

**Problem**: When cache full, what to evict?

**Goal**: Minimize cache misses

**Solution**: Eviction policy

### Cache Operations

**Get**: Retrieve value

**Put**: Store value

**Evict**: Remove value when full

**Hit**: Value found in cache

**Miss**: Value not in cache

## LRU Algorithm

### What is LRU?

**LRU**: Least Recently Used

**Policy**: Evict least recently accessed item

**Intuition**: Recently used likely to be used again

**Use**: Most common cache policy

### LRU Example

**Cache Size**: 3

**Operations**:
```
Put(1, "a")
Put(2, "b")
Put(3, "c")  // Cache: [1,2,3]
Get(1)       // Cache: [2,3,1] (1 moved to end)
Put(4, "d")  // Evict 2, Cache: [3,1,4]
```

**Evicted**: 2 (least recently used)

## LRU Implementation

### Approach 1: Doubly Linked List + HashMap

**Structure**:
```
HashMap: key → Node
Doubly Linked List: Order by recency
```

**Operations**:
- **Get**: Move to end (O(1))
- **Put**: Add to end, evict from front (O(1))

**Code**:
```python
class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}  # key -> node
        self.head = Node(0, 0)
        self.tail = Node(0, 0)
        self.head.next = self.tail
        self.tail.prev = self.head
    
    def get(self, key):
        if key in self.cache:
            node = self.cache[key]
            self._move_to_end(node)
            return node.value
        return -1
    
    def put(self, key, value):
        if key in self.cache:
            node = self.cache[key]
            node.value = value
            self._move_to_end(node)
        else:
            if len(self.cache) >= self.capacity:
                self._evict()
            node = Node(key, value)
            self.cache[key] = node
            self._add_to_end(node)
    
    def _move_to_end(self, node):
        self._remove(node)
        self._add_to_end(node)
    
    def _evict(self):
        lru = self.head.next
        self._remove(lru)
        del self.cache[lru.key]
```

### Approach 2: OrderedDict (Python)

**Simpler**: Use OrderedDict

**Code**:
```python
from collections import OrderedDict

class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = OrderedDict()
    
    def get(self, key):
        if key in self.cache:
            self.cache.move_to_end(key)
            return self.cache[key]
        return -1
    
    def put(self, key, value):
        if key in self.cache:
            self.cache.move_to_end(key)
        else:
            if len(self.cache) >= self.capacity:
                self.cache.popitem(last=False)
        self.cache[key] = value
```

## LFU Algorithm

### What is LFU?

**LFU**: Least Frequently Used

**Policy**: Evict least frequently accessed item

**Intuition**: Frequently used likely to be used again

**Use**: When access frequency matters

### LFU Example

**Cache Size**: 3

**Operations**:
```
Put(1, "a")  // freq: {1:1}
Put(2, "b")  // freq: {1:1, 2:1}
Get(1)       // freq: {1:2, 2:1}
Put(3, "c")  // freq: {1:2, 2:1, 3:1}
Get(2)       // freq: {1:2, 2:2, 3:1}
Put(4, "d")  // Evict 3 (lowest freq), freq: {1:2, 2:2, 4:1}
```

**Evicted**: 3 (least frequently used)

## LFU Implementation

### Data Structures

**1. HashMap**: key → value

**2. Frequency Map**: frequency → LinkedHashSet of keys

**3. Key Frequency Map**: key → frequency

**Code**:
```python
class LFUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}  # key -> value
        self.freq = {}  # key -> frequency
        self.freq_keys = {}  # frequency -> OrderedDict of keys
        self.min_freq = 0
    
    def get(self, key):
        if key not in self.cache:
            return -1
        
        # Update frequency
        old_freq = self.freq[key]
        self.freq[key] = old_freq + 1
        
        # Move to new frequency bucket
        self.freq_keys[old_freq].pop(key)
        if not self.freq_keys[old_freq]:
            del self.freq_keys[old_freq]
            if old_freq == self.min_freq:
                self.min_freq += 1
        
        if self.freq[key] not in self.freq_keys:
            self.freq_keys[self.freq[key]] = OrderedDict()
        self.freq_keys[self.freq[key]][key] = None
        
        return self.cache[key]
    
    def put(self, key, value):
        if self.capacity == 0:
            return
        
        if key in self.cache:
            self.cache[key] = value
            self.get(key)  # Update frequency
        else:
            if len(self.cache) >= self.capacity:
                # Evict LFU
                lfu_key = next(iter(self.freq_keys[self.min_freq]))
                self.freq_keys[self.min_freq].pop(lfu_key)
                del self.cache[lfu_key]
                del self.freq[lfu_key]
            
            # Add new key
            self.cache[key] = value
            self.freq[key] = 1
            self.min_freq = 1
            if 1 not in self.freq_keys:
                self.freq_keys[1] = OrderedDict()
            self.freq_keys[1][key] = None
```

## Other Cache Policies

### FIFO (First In First Out)

**Policy**: Evict oldest item

**Use**: Simple, but not optimal

**Implementation**: Queue

### LIFO (Last In First Out)

**Policy**: Evict newest item

**Use**: Rarely used

**Implementation**: Stack

### Random

**Policy**: Evict random item

**Use**: Baseline comparison

### Optimal (Belady's Algorithm)

**Policy**: Evict item used farthest in future

**Use**: Theoretical optimal (not practical)

**Note**: Requires knowing future

## Comparison

### LRU vs LFU

| Aspect | LRU | LFU |
|--------|-----|-----|
| **Metric** | Recency | Frequency |
| **Use Case** | Temporal locality | Frequency patterns |
| **Complexity** | O(1) | O(1) |
| **Memory** | Lower | Higher |

### When to Use What

**LRU**:
- **Temporal Locality**: Recent items likely reused
- **General Purpose**: Good default
- **Simplicity**: Easier to implement

**LFU**:
- **Frequency Patterns**: Some items accessed more
- **Long-term**: Better for long-term patterns
- **Complexity**: More complex implementation

## Applications

### Application 1: CPU Cache

**Use**: CPU cache eviction

**Policy**: Usually LRU or variants

**Benefit**: Fast memory access

### Application 2: Web Caching

**Use**: Browser cache, CDN

**Policy**: LRU common

**Benefit**: Faster page loads

### Application 3: Database Buffer Pool

**Use**: Database page caching

**Policy**: LRU or clock algorithm

**Benefit**: Reduced disk I/O

### Application 4: Memcached/Redis

**Use**: Distributed caching

**Policy**: Configurable (LRU default)

**Benefit**: Fast data access

## Real-World Examples

### Example 1: Browser Cache

**Policy**: LRU

**Benefit**: Recently visited pages load faster

### Example 2: Database Query Cache

**Policy**: LFU or LRU

**Benefit**: Frequently used queries cached

## Common Pitfalls

### Problem: Not Updating Order

```python
# BAD: Don't update order on access
def get(self, key):
    return self.cache[key]  # Order not updated!

# GOOD: Update order
def get(self, key):
    self._move_to_end(key)  # Update order
    return self.cache[key]
```

### Problem: Wrong Eviction

```python
# BAD: Evict wrong item
# May evict frequently used item

# GOOD: Follow policy correctly
# LRU: Evict least recent
# LFU: Evict least frequent
```

## Quiz

1. What is LRU?
   - **A)** Least Frequently Used
   - **B)** Least Recently Used - evicts least recently accessed item
   - **C)** Last Recently Used
   - **D)** Least Randomly Used

2. What is LFU?
   - **A)** Least Recently Used
   - **B)** Least Frequently Used - evicts least frequently accessed item
   - **C)** Last Frequently Used
   - **D)** Least Finally Used

3. What is the main difference between LRU and LFU?
   - **A)** No difference
   - **B)** LRU uses recency, LFU uses frequency
   - **C)** LRU is faster
   - **D)** LFU is simpler

**Answers:**
1. **B** - LRU (Least Recently Used) evicts the item that was accessed least recently, based on the principle of temporal locality
2. **B** - LFU (Least Frequently Used) evicts the item that has been accessed the fewest times, based on access frequency patterns
3. **B** - LRU tracks when items were last accessed (recency), while LFU tracks how many times items have been accessed (frequency), making them suitable for different access patterns

## Next Steps

- [Disjoint Set Union](../data_structures_algorithms/10.%20Disjoint%20Set%20Union.md) - Union-Find
- [Fenwick Trees](../data_structures_algorithms/11.%20Fenwick%20Trees.md) - Binary Indexed Trees

