---
number: 1
title: "Lock-Free & Wait-Free Algorithms"
slug: "lock-free-wait-free-algorithms"
level: "intermediate"
tags: ["concurrency", "lock-free", "wait-free", "atomic-operations", "algorithms"]
prerequisites: []
estimated_minutes: 120
contributors: []
diagrams: []
examples: []
canonical_id: "cs-conc-01"
---

# Lock-Free & Wait-Free Algorithms

## Overview

Lock-free and wait-free algorithms provide concurrent data structures and algorithms that don't use traditional locks, eliminating deadlocks and improving performance under contention. Understanding atomic operations, compare-and-swap, and lock-free programming techniques is essential for high-performance concurrent systems.

## Table of Contents

1. [Why Lock-Free?](#why-lock-free)
2. [Atomic Operations](#atomic-operations)
3. [Compare-and-Swap (CAS)](#cas)
4. [Lock-Free Algorithms](#lock-free)
5. [Wait-Free Algorithms](#wait-free)
6. [Memory Ordering](#memory-ordering)
7. [Lock-Free Data Structures](#data-structures)
8. [Hazard Pointers](#hazard-pointers)

## Why Lock-Free?

### Problems with Locks

**1. Deadlocks**:
- Circular dependencies
- Complex to avoid
- Hard to debug

**2. Priority Inversion**:
- Low-priority thread holds lock
- High-priority thread blocked
- System performance degrades

**3. Convoy Effect**:
- Slow thread holds lock
- Fast threads wait
- Throughput degrades

**4. Performance Under Contention**:
- Lock contention causes cache line bouncing
- Context switches
- Poor scalability

### Benefits of Lock-Free

**1. No Deadlocks**:
- No locks = no deadlocks
- Simpler reasoning

**2. Better Performance**:
- Under contention: Often faster
- No blocking: Threads make progress
- Better scalability

**3. Fault Tolerance**:
- Thread crash doesn't block others
- System continues operating

**4. Real-Time Guarantees**:
- Bounded operations
- Predictable performance

## Atomic Operations

### What are Atomic Operations?

**Atomic**: Operation completes entirely or not at all

**Characteristics**:
- **Indivisible**: Cannot be interrupted
- **Visible**: Changes visible to all threads
- **Hardware support**: CPU provides atomic instructions

### Common Atomic Operations

**1. Load/Store**:
```c
atomic_int value = ATOMIC_VAR_INIT(0);
atomic_load(&value);      // Atomic read
atomic_store(&value, 10); // Atomic write
```

**2. Fetch-and-Add (FAA)**:
```c
atomic_int counter = ATOMIC_VAR_INIT(0);
int old = atomic_fetch_add(&counter, 1); // Returns old value, adds 1
// counter is now 1, old was 0
```

**3. Compare-and-Swap (CAS)**:
```c
atomic_int value = ATOMIC_VAR_INIT(10);
int expected = 10;
bool success = atomic_compare_exchange_strong(&value, &expected, 20);
// If value == expected, set to 20, return true
// Otherwise, set expected to current value, return false
```

**4. Exchange**:
```c
atomic_int value = ATOMIC_VAR_INIT(10);
int old = atomic_exchange(&value, 20); // Swap atomically
// value is now 20, old was 10
```

### Hardware Support

**x86-64**:
- **LOCK prefix**: Makes instruction atomic
- **CMPXCHG**: Compare-and-exchange
- **XADD**: Exchange-and-add

**ARM**:
- **LDREX/STREX**: Load-linked, store-conditional
- **Atomic operations**: Provided by architecture

## Compare-and-Swap (CAS)

### What is CAS?

**CAS**: Compare-and-Swap (or Compare-and-Exchange)

**Operation**:
```
CAS(ptr, expected, new):
  if (*ptr == expected):
    *ptr = new
    return true
  else:
    return false
```

**Atomic**: Entire operation is atomic

### CAS Loop Pattern

**Common Pattern**:
```c
atomic_int* ptr = ...;
int expected = atomic_load(ptr);

do {
    int new_value = compute_new_value(expected);
} while (!atomic_compare_exchange_weak(ptr, &expected, new_value));
```

**How It Works**:
1. Read current value
2. Compute new value
3. Try to update with CAS
4. If failed (value changed), retry

### CAS Example: Lock-Free Counter

```c
typedef struct {
    atomic_int count;
} lock_free_counter;

void increment(lock_free_counter* c) {
    int expected = atomic_load(&c->count);
    int desired;
    
    do {
        desired = expected + 1;
    } while (!atomic_compare_exchange_weak(&c->count, &expected, desired));
}

int get(lock_free_counter* c) {
    return atomic_load(&c->count);
}
```

**Benefits**:
- **No locks**: No blocking
- **Scalable**: Multiple threads can increment
- **Progress**: At least one thread makes progress

## Lock-Free Algorithms

### What is Lock-Free?

**Lock-Free**: System-wide progress guaranteed

**Definition**: If some thread is running, at least one thread makes progress

**Not Required**: Every thread makes progress

**Key Point**: System doesn't deadlock

### Lock-Free Stack

**Node Structure**:
```c
typedef struct node {
    int data;
    struct node* next;
} node;

typedef struct {
    atomic_node_ptr top;
} lock_free_stack;
```

**Push Operation**:
```c
void push(lock_free_stack* s, int data) {
    node* new_node = malloc(sizeof(node));
    new_node->data = data;
    node* old_top;
    
    do {
        old_top = atomic_load(&s->top);
        new_node->next = old_top;
    } while (!atomic_compare_exchange_weak(&s->top, &old_top, new_node));
}
```

**Pop Operation**:
```c
int pop(lock_free_stack* s) {
    node* old_top;
    node* new_top;
    
    do {
        old_top = atomic_load(&s->top);
        if (old_top == NULL) {
            return -1; // Empty
        }
        new_top = old_top->next;
    } while (!atomic_compare_exchange_weak(&s->top, &old_top, new_top));
    
    int data = old_top->data;
    free(old_top); // ABA problem!
    return data;
}
```

### ABA Problem

**Problem**: Value changes A→B→A, CAS succeeds incorrectly

**Example**:
```
Thread 1: Reads top = A
Thread 2: Pops A, pushes B, pushes A (reuses same node)
Thread 1: CAS succeeds (A == A), but structure changed!
```

**Solution**: 
- **Version numbers**: Tag pointers with version
- **Hazard pointers**: Don't free immediately
- **GC**: Garbage collection prevents reuse

## Wait-Free Algorithms

### What is Wait-Free?

**Wait-Free**: Every thread makes progress

**Definition**: Every operation completes in bounded steps

**Stronger**: Than lock-free (every thread progresses)

**Guarantee**: No thread can be delayed by others

### Wait-Free Counter

**Simple Example**:
```c
typedef struct {
    atomic_int counters[THREAD_COUNT];
} wait_free_counter;

void increment(wait_free_counter* c, int thread_id) {
    atomic_fetch_add(&c->counters[thread_id], 1);
}

int get(wait_free_counter* c) {
    int sum = 0;
    for (int i = 0; i < THREAD_COUNT; i++) {
        sum += atomic_load(&c->counters[i]);
    }
    return sum;
}
```

**Characteristics**:
- **Per-thread counter**: No contention
- **Bounded steps**: O(thread_count) to read
- **Wait-free**: Every operation completes

### Wait-Free vs Lock-Free

**Lock-Free**:
- **Progress**: At least one thread progresses
- **Others**: May retry indefinitely
- **Example**: CAS-based stack

**Wait-Free**:
- **Progress**: Every thread progresses
- **Bounded**: Operations complete in bounded steps
- **Example**: Per-thread counters

**Trade-off**: Wait-free often slower (more overhead)

## Memory Ordering

### The Problem

**Out-of-Order Execution**: CPU may reorder instructions

**Example**:
```c
// Thread 1
x = 1;
y = 2;

// Thread 2
if (y == 2) {
    assert(x == 1); // May fail! (reordering)
}
```

**Why**: CPU optimizations, compiler optimizations

### Memory Ordering Models

**1. Sequential Consistency**:
- **Strongest**: All operations appear in program order
- **Cost**: Expensive, limits optimizations

**2. Acquire-Release**:
- **Acquire**: All reads after acquire see writes before release
- **Release**: All writes before release visible after acquire
- **Common**: Good balance

**3. Relaxed**:
- **Weakest**: No ordering guarantees
- **Use**: Counters, flags

### C11 Memory Ordering

```c
// Sequential consistency (strongest)
atomic_store_explicit(&x, 1, memory_order_seq_cst);

// Acquire-Release
atomic_store_explicit(&x, 1, memory_order_release);
int val = atomic_load_explicit(&y, memory_order_acquire);

// Relaxed (weakest)
atomic_store_explicit(&x, 1, memory_order_relaxed);
```

## Lock-Free Data Structures

### Lock-Free Queue

**Michael & Scott Algorithm**:
```c
typedef struct node {
    void* data;
    atomic_node_ptr next;
} node;

typedef struct {
    atomic_node_ptr head;
    atomic_node_ptr tail;
} lock_free_queue;

void enqueue(lock_free_queue* q, void* data) {
    node* new_node = malloc(sizeof(node));
    new_node->data = data;
    new_node->next = NULL;
    
    node* tail;
    node* next;
    
    while (true) {
        tail = atomic_load(&q->tail);
        next = atomic_load(&tail->next);
        
        if (tail == atomic_load(&q->tail)) {
            if (next == NULL) {
                if (atomic_compare_exchange_weak(&tail->next, &next, new_node)) {
                    break;
                }
            } else {
                atomic_compare_exchange_weak(&q->tail, &tail, next);
            }
        }
    }
    
    atomic_compare_exchange_weak(&q->tail, &tail, new_node);
}
```

### Lock-Free Hash Table

**Chaining with Lock-Free Lists**:
```c
typedef struct {
    lock_free_list* buckets[BUCKET_COUNT];
} lock_free_hash_table;

void insert(lock_free_hash_table* ht, int key, void* value) {
    int bucket = hash(key) % BUCKET_COUNT;
    lock_free_list_insert(ht->buckets[bucket], key, value);
}
```

## Hazard Pointers

### The Problem

**Memory Reclamation**: When to free nodes?

**Problem**: 
- Thread A: Reads pointer to node
- Thread B: Removes node, frees it
- Thread A: Uses freed node → Use-after-free!

### Hazard Pointer Solution

**Idea**: Protect pointers currently in use

**Algorithm**:
```c
// Per-thread hazard pointers
__thread void* hazard_pointers[HAZARD_POINTER_COUNT];

// Read with hazard pointer
void* read_with_hazard(lock_free_list* list, int index) {
    void* ptr = atomic_load(&list->head);
    hazard_pointers[index] = ptr; // Protect
    return ptr;
}

// Free only if not hazard
void safe_free(void* ptr) {
    // Check if any thread has this as hazard pointer
    if (!is_hazard(ptr)) {
        free(ptr);
    } else {
        // Defer freeing
        defer_free(ptr);
    }
}
```

**Benefits**:
- **Safe**: Prevents use-after-free
- **Efficient**: Minimal overhead
- **Practical**: Used in real systems

## Real-World Examples

### Example 1: Lock-Free Counter

**Use Case**: High-contention counter

```c
// Lock-free counter (better under contention)
lock_free_counter counter;
for (int i = 0; i < NUM_THREADS; i++) {
    create_thread(increment_loop, &counter);
}

// vs Locked counter (worse under contention)
pthread_mutex_t mutex;
int counter = 0;
for (int i = 0; i < NUM_THREADS; i++) {
    create_thread(increment_locked, &counter);
}
```

**Result**: Lock-free often faster under high contention

### Example 2: Lock-Free Queue

**Use Case**: Producer-consumer

```c
lock_free_queue queue;

// Producer
void producer() {
    for (int i = 0; i < NUM_ITEMS; i++) {
        enqueue(&queue, create_item(i));
    }
}

// Consumer
void consumer() {
    while (true) {
        void* item = dequeue(&queue);
        if (item) {
            process(item);
        }
    }
}
```

**Benefits**: No blocking, better throughput

## Common Pitfalls

### Problem: ABA Problem

```c
// BAD: ABA problem
node* old_top = atomic_load(&stack->top);
node* new_top = old_top->next;
// Another thread: pop, push (reuses node)
atomic_compare_exchange_weak(&stack->top, &old_top, new_top);
// Succeeds incorrectly!

// GOOD: Use version numbers or hazard pointers
```

### Problem: Memory Ordering

```c
// BAD: Wrong memory ordering
atomic_store(&flag, 1); // May be reordered
data = compute();

// GOOD: Use acquire-release
atomic_store_explicit(&flag, 1, memory_order_release);
```

## Quiz

1. What is the main advantage of lock-free algorithms?
   - **A)** Simpler code
   - **B)** No deadlocks and better performance under contention
   - **C)** Always faster
   - **D)** Easier to debug

2. What is the ABA problem?
   - **A)** Algorithm too complex
   - **B)** Value changes A→B→A, CAS succeeds incorrectly
   - **C)** Atomic operations fail
   - **D)** Memory leak

3. What is the difference between lock-free and wait-free?
   - **A)** No difference
   - **B)** Lock-free guarantees at least one thread progresses, wait-free guarantees every thread progresses
   - **C)** Wait-free uses locks
   - **D)** Lock-free is faster

**Answers:**
1. **B** - Lock-free algorithms eliminate deadlocks and often perform better under high contention because threads don't block
2. **B** - ABA problem occurs when a value changes from A to B and back to A, causing CAS to succeed incorrectly because it only compares values, not the actual state
3. **B** - Lock-free guarantees system-wide progress (at least one thread makes progress), while wait-free guarantees every thread makes progress in bounded steps

## Next Steps

- [Atomic Operations & CAS](./02.%20Atomic%20Operations%20%26%20CAS.md) - Deep dive into atomics
- [Memory Models & Happens-Before](./03.%20Memory%20Models%20%26%20Happens-Before.md) - Memory consistency

